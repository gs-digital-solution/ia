import requests
import os
import tempfile
import json
import re
import numpy as np
import cv2
from pdf2image import convert_from_path
import matplotlib
import openai
from .pdf_utils import generer_pdf_corrige
from datetime import datetime
import logging
import camelot
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from pdfminer.high_level import extract_text
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
from django.conf import settings
from django.utils.safestring import mark_safe
from celery import shared_task
from PIL import Image
import base64
from resources.models import PromptIA,Matiere
from .pdf_utils import generer_pdf_corrige
from .models import SoumissionIA
from resources.models import Matiere
from abonnement.services import debiter_credit_abonnement
from .models import CorrigePartiel
from django.core.files import File
import time
from datetime import datetime
#from .tasks import generer_un_exercice
#from celery import group
import logging
# Logger d√©di√©
logger = logging.getLogger(__name__)

mathpix_logger = logging.getLogger('mathpix')
def log_extraction_method(demande, method, success=True):
    """Journaliser la m√©thode d'extraction utilis√©e"""
    if demande:
        dept = demande.departement.nom if demande.departement else "inconnu"
        mathpix_logger.info(
            f"üìä Extraction - D√©partement: {dept}, "
            f"M√©thode: {method}, Succ√®s: {success}"
        )


def extraire_avec_mathpix(fichier_path: str) -> dict:
    """
    Extraction avec Mathpix ‚Äì g√®re les images et les PDF multi-pages.
    Pour les PDF, convertit et traite TOUTES les pages, puis concat√®ne les r√©sultats.
    Retourne le texte avec les formules format√©es pour MathJax.
    """
    headers = {
        "app_id": os.getenv("MATHPIX_APP_ID"),
        "app_key": os.getenv("MATHPIX_APP_KEY"),
        "Content-type": "application/json"
    }

    ext = os.path.splitext(fichier_path)[1].lower()
    logger.info(f"üìÅ Fichier re√ßu par Mathpix: {ext}")

    temp_files = []
    all_text_parts = []
    all_latex_blocks = []

    try:
        # === 1. GESTION DES PDF (conversion de TOUTES les pages) ===
        if ext == '.pdf':
            logger.info("üìÑ PDF d√©tect√©, conversion de toutes les pages en images...")
            from pdf2image import convert_from_path

            # Convertir TOUTES les pages du PDF
            images = convert_from_path(
                fichier_path,
                dpi=300  # Bonne r√©solution pour l'OCR
            )

            logger.info(f"   {len(images)} page(s) trouv√©e(s)")

            # Traiter chaque page une par une
            for page_num, image in enumerate(images, 1):
                logger.info(f"   üîÑ Traitement page {page_num}/{len(images)}...")

                # Sauvegarder temporairement la page
                temp_img = tempfile.NamedTemporaryFile(suffix='.png', delete=False)
                temp_img.close()
                image.save(temp_img.name, 'PNG')
                temp_files.append(temp_img.name)

                # Lire l'image
                with open(temp_img.name, "rb") as f:
                    image_data = base64.b64encode(f.read()).decode()

                # Appel √† Mathpix pour cette page
                data = {
                    "src": f"data:image/jpeg;base64,{image_data}",
                    "formats": ["text", "latex_styled"],
                    "ocr": ["math", "text"],
                    "skip_recrop": False,
                    "math_inline_delimiters": ["$", "$"],
                    "rm_spaces": True,
                    "format": "text"
                }

                try:
                    response = requests.post(
                        os.getenv("MATHPIX_API_URL", "https://api.mathpix.com/v3/text"),
                        headers=headers,
                        data=json.dumps(data),
                        timeout=30
                    )

                    if response.status_code == 200:
                        result = response.json()
                        page_texte = result.get("text", "")
                        page_latex = result.get("latex_styled", [])

                        # Ajouter un s√©parateur de page pour la lisibilit√©
                        if page_texte:
                            all_text_parts.append(f"[Page {page_num}]\n{page_texte}")
                        else:
                            all_text_parts.append(f"[Page {page_num} - vide]")

                        all_latex_blocks.extend(page_latex)

                        logger.info(f"   ‚úÖ Page {page_num}: {len(page_texte)} caract√®res")
                    else:
                        logger.warning(f"   ‚ö†Ô∏è Page {page_num}: erreur {response.status_code}")
                        all_text_parts.append(f"[Page {page_num} - erreur]")

                except Exception as e:
                    logger.warning(f"   ‚ö†Ô∏è Page {page_num}: exception {e}")
                    all_text_parts.append(f"[Page {page_num} - exception]")

                # Petite pause pour √©viter de surcharger l'API
                time.sleep(0.5)

        # === 2. GESTION DES IMAGES (une seule page) ===
        else:
            logger.info("üñºÔ∏è Image d√©tect√©e, traitement direct...")
            with open(fichier_path, "rb") as f:
                image_data = base64.b64encode(f.read()).decode()

            data = {
                "src": f"data:image/jpeg;base64,{image_data}",
                "formats": ["text", "latex_styled"],
                "ocr": ["math", "text"],
                "skip_recrop": False,
                "math_inline_delimiters": ["$", "$"],
                "rm_spaces": True,
                "format": "text"
            }

            response = requests.post(
                os.getenv("MATHPIX_API_URL", "https://api.mathpix.com/v3/text"),
                headers=headers,
                data=json.dumps(data),
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                all_text_parts = [result.get("text", "")]
                all_latex_blocks = result.get("latex_styled", [])
                logger.info(f"‚úÖ Image trait√©e: {len(all_text_parts[0])} caract√®res")
            else:
                logger.error(f"‚ùå Mathpix error {response.status_code}")
                return {"text": "", "latex_blocks": [], "source": "error"}

        # === 3. CONCAT√âNATION ET FORMATAGE FINAL ===
        texte_complet = "\n\n".join(all_text_parts)

        # Formatage global pour MathJax
        texte_complet = re.sub(
            r'\$\$(.*?)\$\$',
            lambda m: '\\[' + m.group(1).strip() + '\\]',
            texte_complet,
            flags=re.DOTALL
        )

        texte_complet = re.sub(
            r'(?<!\$)\$(?!\$)(.*?)(?<!\$)\$(?!\$)',
            lambda m: '\\(' + m.group(1).strip() + '\\)',
            texte_complet,
            flags=re.DOTALL
        )

        logger.info(
            f"‚úÖ Extraction termin√©e: {len(texte_complet)} caract√®res au total, {len(all_latex_blocks)} blocs LaTeX")

        return {
            "text": texte_complet,
            "latex_blocks": all_latex_blocks,
            "source": "mathpix",
            "pages_traitees": len(images) if ext == '.pdf' else 1
        }

    except Exception as e:
        logger.error(f"‚ùå Mathpix exception: {e}")
        import traceback
        traceback.print_exc()
        return {"text": "", "latex_blocks": [], "source": "error"}

    finally:
        # === 4. NETTOYAGE ===
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)
                    logger.debug(f"üßπ Fichier temporaire supprim√©: {temp_file}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Impossible de supprimer {temp_file}: {e}")

def preprocess_image_for_ocr(pil_image):
    """
    Convertit une PIL.Image en image binaire nettoy√©e pour Tesseract.
    """
    # PIL ‚Üí CV2 BGR
    img = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    # niveaux de gris
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # seuillage adaptatif
    bin_img = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        blockSize=11,
        C=2
    )
    # ouverture pour nettoyer le petit bruit
    kernel = np.ones((1,1), np.uint8)
    clean = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel)
    return clean

# Cache en m√©moire des PromptIA pour √©viter les hits r√©p√©t√©s en BDD
_PROMPTIA_CACHE = {}

# ========== BLIP LAZY-LOADER ==========
_blip_model = None
_blip_processor = None
def get_blip_model():
    """
    Charge le mod√®le BLIP au premier appel (lazy load).
    """
    global _blip_model, _blip_processor
    if _blip_model is None:
        import torch
        from transformers import BlipProcessor, BlipForConditionalGeneration
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        _blip_processor = BlipProcessor.from_pretrained(
            "Salesforce/blip-image-captioning-base"
        )
        _blip_model = BlipForConditionalGeneration.from_pretrained(
            "Salesforce/blip-image-captioning-base"
        ).to(device).eval()
        logger.info("üñºÔ∏è BLIP charg√© sur %s", device)
    return _blip_processor, _blip_model


DEPARTEMENTS_SCIENTIFIQUES = [
    'math√©matiques', 'physique', 'chimie', 'biologie',
    'svt', 'sciences', 'informatique', 'anglais'
    # Ajouter des variantes
    'maths', 'mathematiques', 'math', 'physique-chimie',
    'science', 'scientifique', 'biologie-g√©ologie'
]


def is_departement_scientifique(departement):
    """
    Renvoie True si le d√©partement fait partie des fili√®res scientifiques.
    Version robuste avec plusieurs variantes.
    """
    if not departement or not departement.nom:
        return False

    dep_name = departement.nom.strip().lower()

    # Liste √©tendue de termes scientifiques
    scientific_terms = [
        'math', 'physique', 'chimie', 'biologie', 'svt',
        'science', 'informatique', 'technologie', 'g√©ologie',
        'astronomie', '√©cologie', 'g√©n√©tique', '√©lectricit√©',
        'm√©canique', 'optique', 'thermodynamique', 'statistique',
        'alg√®bre', 'g√©om√©trie', 'analyse', 'calcul', 'num√©rique'
    ]

    # V√©rification simple
    for term in scientific_terms:
        if term in dep_name:
            print(f"‚úÖ D√©partement '{dep_name}' reconnu comme scientifique (contient '{term}')")
            return True

    # V√©rification sp√©cifique pour les d√©buts de mots
    for term in DEPARTEMENTS_SCIENTIFIQUES:
        if dep_name.startswith(term):
            print(f"‚úÖ D√©partement '{dep_name}' commence par '{term}' ‚Üí scientifique")
            return True

    print(f"‚ùå D√©partement '{dep_name}' non reconnu comme scientifique")
    return False


# ‚îÄ‚îÄ CODE D'EXTRACTION DU PROMPT LE PLUS SPECIFIQUE POSSIBLE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def get_best_promptia(demande):
    """
    Retourne le PromptIA le plus sp√©cifique pour la demande, ou None.
    Ne fait jamais filter({}) qui retomberait sur le 1er prompt anglais.
    Fallback progressif, puis prompt par d√©faut si rien trouv√©.
    """
    # 1) Construire le filtre initial
    filtra = {
        'pays': demande.pays,
        'sous_systeme': demande.sous_systeme,
        'classe': demande.classe,
        'matiere': demande.matiere,
        'departement': demande.departement,
        'type_exercice': demande.type_exercice,
    }
    # Ne garder que les cl√©s non-nulles
    filtra = {k: v for k, v in filtra.items() if v is not None}

    # 2) Si on a au moins un crit√®re, tenter la recherche exacte
    if filtra:
        qs = PromptIA.objects.filter(**filtra)
        if qs.exists():
            return qs.first()

        # 2b) Fallback progressif en retirant un champ √† la fois
        for champ in ['type_exercice', 'departement', 'classe', 'sous_systeme', 'pays']:
            if champ in filtra:
                filtra2 = dict(filtra)
                filtra2.pop(champ)
                if filtra2:
                    qs2 = PromptIA.objects.filter(**filtra2)
                    if qs2.exists():
                        return qs2.first()

        # 2c) Fallback par mati√®re seule si mati√®re faisait partie du filtre
        if 'matiere' in filtra:
            qs3 = PromptIA.objects.filter(matiere=demande.matiere)
            if qs3.exists():
                return qs3.first()

    # 3) Aucune correspondance : retomber sur DEFAULT_SYSTEM_PROMPT
    return None


# ‚îÄ‚îÄ CONFIGURATION DEEPSEEK AVEC VISION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
openai.api_key = os.getenv("DEEPSEEK_API_KEY")
openai.api_base = "https://api.deepseek.com"

# ‚îÄ‚îÄ MOD√àLE POUR LA VISION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# deepseek-chat a les capacit√©s vision quand on envoie des images
DEEPSEEK_VISION_MODEL = "deepseek-reasoner"


# ‚îÄ‚îÄ‚îÄ NEW ‚îÄ‚îÄ‚îÄ appel multimodal √† DeepSeek-V3 pour PDF / images ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚îÄ‚îÄ CORRIG√â : Appel multimodal √† DeepSeek pour PDF/images ‚îÄ‚îÄ‚îÄ‚îÄ
def call_deepseek_vision(path_fichier: str) -> dict:
    """
    Envoie un PDF ou une image √† DeepSeek - Version corrig√©e pour l'API DeepSeek.
    """
    system_prompt = r"""
    Tu es un expert en sch√©mas et documents scientifiques.
    Prends cette image ou ce PDF (base64) et renvoie **SEULEMENT** un JSON structur√© :
    {
      "text": "<le texte complet>",
      "latex_blocks": ["‚Ä¶","‚Ä¶"],
      "captions": ["l√©gende du sch√©ma", ‚Ä¶],
      "graphs": [ { ‚Ä¶ donn√©es graphiques ‚Ä¶ } ],
      "angles": [ {"valeur":30,"unit√©":"¬∞","coord":[x,y]}, ‚Ä¶ ],
      "numbers": [ {"valeur":9.81,"unit√©":"m/s¬≤","coord":[x,y]}, ‚Ä¶ ]
    }
    Ne renvoie aucun texte hors de ce JSON.
    """
    try:
        # Encoder le fichier en base64
        with open(path_fichier, "rb") as f:
            data_b64 = base64.b64encode(f.read()).decode("utf-8")

        # ‚úÖ CORRECTION : Format DeepSeek compatible
        message_content = f"""
        [image]{data_b64}[/image]

        Extrait le texte, les formules LaTeX et les l√©gendes de ce document.
        """

        response = openai.ChatCompletion.create(
            model=DEEPSEEK_VISION_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message_content}
            ],
            response_format={"type": "json_object"},
            temperature=0.0,
            max_tokens=8000
        )

        content = response.choices[0].message.content
        return content if isinstance(content, dict) else json.loads(content)

    except Exception as e:
        print(f"‚ùå Erreur call_deepseek_vision: {e}")
        return {"text": "", "latex_blocks": [], "captions": [], "graphs": []}


# ============== NOUVELLE FONCTION: DeepSeek Vision Am√©lior√©e avec extraction structur√©e ==============
def call_deepseek_vision_ameliore(path_fichier: str, demande=None) -> dict:
    """
    Appel DeepSeek am√©lior√© avec timeout long (120s) et redimensionnement automatique des images.
    Version optimis√©e pour g√©rer les images volumineuses et les timeouts.
    """
    logger.info(f"üîÑ Appel DeepSeek Vision Am√©lior√© pour {path_fichier}")

    # V√©rification cl√© API
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        logger.error("‚ùå DEEPSEEK_API_KEY non configur√©e")
        return {"exercices": [], "texte_complet": "", "elements_visuels": []}

    # V√©rification fichier
    if not os.path.exists(path_fichier):
        logger.error(f"‚ùå Fichier non trouv√©: {path_fichier}")
        return {"exercices": [], "texte_complet": "", "elements_visuels": []}

    # Taille du fichier
    file_size = os.path.getsize(path_fichier)
    logger.info(f"üìÅ Taille fichier originale: {file_size} octets ({file_size/1024:.1f} Ko)")

    system_prompt = """
    Tu es un expert en reconnaissance de textes et sch√©mas dans des documents scolaires.

    INSTRUCTIONS ABSOLUES:
    1. Ce document est un SUJET D'EXAMEN. Il contient du texte et des sch√©mas.
    2. Tu dois EXTRAIRE le texte EXACTEMENT comme il appara√Æt, sans modification, sans r√©√©criture.
    3. Tu dois IDENTIFIER la structure du document (exercices, parties).
    4. Tu dois D√âCRIRE les sch√©mas en d√©tail.

    R√àGLE D'OR: Ne r√©√©cris PAS l'√©nonc√©. Recopie-le mot pour mot, avec les m√™mes phrases, les m√™mes mots.

    EXEMPLE:
    Si le texte dit "Dans la cour de r√©cr√©ation, l'√©l√®ve Mbonto se vante", tu dois √©crire exactement cela.
    Tu ne dois PAS √©crire "Un √©l√®ve se vante dans la cour".

    POUR LES SCH√âMAS:
    - D√©cris leur type (circuit, figure, graphique, plan inclin√©, etc.)
    - D√©cris les √©l√©ments visibles et leur position
    - D√©cris les relations entre √©l√©ments
    - Extrais toutes les valeurs num√©riques (angles, longueurs, tensions)

    RENVOIE UNIQUEMENT CE JSON:
    {
      "exercices": [
        {
          "titre": "titre exact de l'exercice",
          "texte": "texte exact recopi√© sans modification",
          "schemas": [
            {
              "type_schema": "type de sch√©ma",
              "description": "description d√©taill√©e",
              "elements": ["√©l√©ment1", "√©l√©ment2"],
              "relations": "relations entre √©l√©ments",
              "valeurs": {"angle": "30¬∞", "longueur": "70cm"}
            }
          ],
          "formules": ["$formule1$", "$formule2$"]
        }
      ]
    }
    """

    try:
        # ========== REDIMENSIONNEMENT INTELLIGENT DE L'IMAGE ==========
        from PIL import Image
        import io

        logger.info("üìñ Lecture et optimisation de l'image...")

        # Ouvrir l'image avec PIL
        img = Image.open(path_fichier)

        # Log des dimensions originales
        original_width, original_height = img.size
        logger.info(f"üìê Dimensions originales: {original_width}x{original_height}")

        # Redimensionner si trop grande (max 1200px de c√¥t√©)
        max_dimension = 1200
        if original_width > max_dimension or original_height > max_dimension:
            # Calculer le ratio de redimensionnement
            ratio = min(max_dimension / original_width, max_dimension / original_height)
            new_width = int(original_width * ratio)
            new_height = int(original_height * ratio)

            # Redimensionner avec conservation de la qualit√©
            img.thumbnail((max_dimension, max_dimension), Image.Resampling.LANCZOS)
            logger.info(f"üìê Image redimensionn√©e: {new_width}x{new_height} (ratio: {ratio:.2f})")

        # Convertir en RGB si n√©cessaire (pour les PNG avec transparence)
        if img.mode in ('RGBA', 'P'):
            img = img.convert('RGB')

        # Sauvegarder en JPEG avec compression optimale
        buffer = io.BytesIO()
        img.save(buffer, format='JPEG', quality=85, optimize=True)
        compressed_size = len(buffer.getvalue())
        logger.info(f"üì¶ Taille apr√®s compression: {compressed_size} octets ({compressed_size/1024:.1f} Ko)")

        # Encodage en base64
        data_b64 = base64.b64encode(buffer.getvalue()).decode("utf-8")
        logger.info(f"üîê Base64: {len(data_b64)} caract√®res ({len(data_b64)/1024:.1f} Ko)")

        # V√©rification taille base64 (limite DeepSeek ~500Ko)
        if len(data_b64) > 600000:  # ~450 Ko apr√®s d√©codage
            logger.warning(f"‚ö†Ô∏è Image encore trop grande ({len(data_b64)/1024:.1f} Ko), compression plus forte...")

            # Recompression avec qualit√© plus faible
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=60, optimize=True)
            data_b64 = base64.b64encode(buffer.getvalue()).decode("utf-8")
            logger.info(f"üì¶ Apr√®s compression renforc√©e: {len(data_b64)/1024:.1f} Ko")

        # Construction du message
        message_content = f"[image]{data_b64}[/image]\n\nExtrais le texte et les exercices exactement comme dans l'image."

        # Appel API avec timeout long
        logger.info("üì° Envoi requ√™te √† DeepSeek (timeout 120s)...")

        import requests

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message_content}
            ],
            "response_format": {"type": "json_object"},
            "temperature": 0.0,
            "max_tokens": 8000  # Augment√© pour les descriptions d√©taill√©es
        }

        logger.info(f"üì§ Taille payload: {len(str(payload))/1024:.1f} Ko")

        # Timeout long (120 secondes)
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=120,  # 2 minutes
            stream=False
        )

        logger.info(f"üì° R√©ponse re√ßue: status {response.status_code}")

        if response.status_code != 200:
            logger.error(f"‚ùå Erreur HTTP {response.status_code}: {response.text[:500]}")
            return {"exercices": [], "texte_complet": "", "elements_visuels": []}

        result = response.json()

        # V√©rification de la structure de la r√©ponse
        if 'choices' not in result or not result['choices']:
            logger.error(f"‚ùå Structure r√©ponse invalide: {result}")
            return {"exercices": [], "texte_complet": "", "elements_visuels": []}

        content = result['choices'][0]['message']['content']
        logger.info(f"üì¶ R√©ponse brute ({len(content)} caract√®res): {content[:300]}...")

        # Nettoyage de la r√©ponse (enlever les markdown json √©ventuels)
        content = re.sub(r'```json\s*', '', content)
        content = re.sub(r'\s*```', '', content)
        content = content.strip()

        # Parser le JSON
        try:
            resultat = json.loads(content)

            # Validation de la structure
            if "exercices" not in resultat:
                logger.warning("‚ö†Ô∏è Structure JSON incorrecte (pas de cl√© 'exercices')")
                # Tentative de correction
                if isinstance(resultat, list):
                    resultat = {"exercices": resultat}
                elif isinstance(resultat, dict) and len(resultat) == 1:
                    # Prendre la premi√®re cl√© comme exercices
                    first_key = list(resultat.keys())[0]
                    resultat = {"exercices": resultat[first_key]}

            nb_exercices = len(resultat.get('exercices', []))
            logger.info(f"‚úÖ Parsing r√©ussi: {nb_exercices} exercices")

            # Log des sch√©mas d√©tect√©s
            if nb_exercices > 0:
                for i, ex in enumerate(resultat['exercices']):
                    nb_schemas = len(ex.get('schemas', []))
                    logger.info(f"   Exercice {i+1}: {nb_schemas} sch√©ma(s)")

            return resultat

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON invalide: {e}")
            logger.error(f"Contenu: {content[:500]}")

            # Tentative de r√©cup√©ration avec regex
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                try:
                    resultat = json.loads(json_match.group())
                    logger.info(f"‚úÖ JSON r√©cup√©r√© par regex: {len(resultat.get('exercices', []))} exercices")
                    return resultat
                except:
                    pass

            return {"exercices": [], "texte_complet": "", "elements_visuels": []}

    except requests.exceptions.Timeout:
        logger.error("‚ùå Timeout DeepSeek (120s d√©pass√©)")
        return {"exercices": [], "texte_complet": "", "elements_visuels": []}

    except requests.exceptions.ConnectionError as e:
        logger.error(f"‚ùå Erreur connexion DeepSeek: {e}")
        return {"exercices": [], "texte_complet": "", "elements_visuels": []}

    except Exception as e:
        logger.error(f"‚ùå Erreur DeepSeek: {type(e).__name__}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {"exercices": [], "texte_complet": "", "elements_visuels": []}

# ‚îÄ‚îÄ NOUVELLE FONCTION : Analyse scientifique avanc√©e ‚îÄ‚îÄ‚îÄ‚îÄ

def analyser_document_scientifique(fichier_path: str, demande=None) -> dict:
    """
    Analyse scientifique avanc√©e - Version DeepSeek First
    Pour les d√©partements scientifiques : DeepSeek Vision (texte + sch√©mas)
    Fallback : Mathpix (si DeepSeek √©choue) ou OCR standard
    """
    logger.info(f"üîç D√©but analyse scientifique pour {fichier_path}")

    # 1) D√âTECTION DU D√âPARTEMENT POUR CHOIX DE LA M√âTHODE
    use_deepseek = False
    dept_nom = "inconnu"

    if demande and demande.departement:
        dept_nom = demande.departement.nom
        use_deepseek = is_departement_scientifique(demande.departement)
        logger.info(f"üìä D√©partement '{dept_nom}' ‚Üí DeepSeek = {use_deepseek}")

    # 2) PRIORIT√â: DEEPSEEK POUR D√âPARTEMENTS SCIENTIFIQUES
    if use_deepseek:
        logger.info("üß† Extraction avec DeepSeek Vision (d√©partement scientifique)")

        try:
            resultat_deepseek = call_deepseek_vision_ameliore(fichier_path, demande)

            # V√©rifier que le r√©sultat est utilisable
            texte = resultat_deepseek.get("texte_complet", "")
            if texte and len(texte) > 100:
                logger.info(f"‚úÖ DeepSeek r√©ussi: {len(texte)} caract√®res, "
                            f"{len(resultat_deepseek.get('exercices', []))} exercices, "
                            f"{len(resultat_deepseek.get('elements_visuels', []))} sch√©mas")

                return {
                    "texte_complet": texte,
                    "elements_visuels": resultat_deepseek.get("elements_visuels", []),
                    "formules_latex": resultat_deepseek.get("latex_blocks", []),
                    "graphs": [],  # Sera extrait des exercices si besoin
                    "angles": [],
                    "numbers": [],
                    "structure_exercices": resultat_deepseek.get("exercices", []),
                    "source_extraction": "deepseek",
                    "departement": dept_nom,
                    "exercices_struct": resultat_deepseek.get("exercices", [])  # NOUVEAU: structure compl√®te
                }
            else:
                logger.warning("‚ö†Ô∏è DeepSeek √©chec ou r√©sultat trop court (<100 chars), fallback Mathpix")
                use_deepseek = False

        except Exception as e:
            logger.error(f"‚ùå DeepSeek exception: {e}")
            import traceback
            traceback.print_exc()
            use_deepseek = False

    # 3) FALLBACK 1: MATHPIX (si DeepSeek a √©chou√© mais que Mathpix est configur√©)
    if not use_deepseek and os.getenv("MATHPIX_APP_ID") and os.getenv("MATHPIX_APP_KEY"):
        logger.info("üßÆ Fallback avec Mathpix")

        resultat_mathpix = extraire_avec_mathpix(fichier_path)

        if resultat_mathpix.get("text") and len(resultat_mathpix["text"]) > 100:
            logger.info(f"‚úÖ Mathpix r√©ussi: {len(resultat_mathpix['text'])} caract√®res")

            return {
                "texte_complet": resultat_mathpix["text"],
                "elements_visuels": [],
                "formules_latex": resultat_mathpix.get("latex_blocks", []),
                "graphs": [],
                "angles": [],
                "numbers": [],
                "structure_exercices": [],
                "source_extraction": "mathpix",
                "departement": dept_nom,
                "exercices_struct": []  # Pas de structure d'exercices
            }
        else:
            logger.warning("‚ö†Ô∏è Mathpix √©chec, fallback standard")

    # 4) FALLBACK 2: ANALYSE STANDARD (OCR uniquement)
    logger.info("üî§ Fallback final: OCR standard")

    # Code OCR standard existant (√† garder tel quel)
    config_tesseract = r'--oem 3 --psm 6 -l fra+eng+digits'
    texte_ocr = ""

    try:
        if fichier_path.lower().endswith(('.png', '.jpg', '.jpeg')):
            img = Image.open(fichier_path)
            clean = preprocess_image_for_ocr(img)
            texte_ocr = pytesseract.image_to_string(clean, config=config_tesseract)
            logger.info(f"    ‚úì OCR image brut extrait {len(texte_ocr)} caract√®res")

        elif fichier_path.lower().endswith('.pdf'):
            texte_ocr = extraire_texte_pdf(fichier_path)
            logger.info(f"    ‚úì PDFMiner extrait {len(texte_ocr)} caract√®res")

            if len(texte_ocr) < 50:
                logger.warning("    ‚ö†Ô∏è OCR PDFMiner trop court, fallback page √† page")
                pages = convert_from_path(fichier_path, dpi=300)
                txts = []
                for page in pages:
                    clean = preprocess_image_for_ocr(page)
                    txts.append(pytesseract.image_to_string(clean, config=config_tesseract))
                texte_ocr = "\n".join(txts)
                logger.info(f"    ‚úì fallback OCR pages donne {len(texte_ocr)} caract√®res")
    except Exception as e:
        logger.error(f"‚ùå Erreur pendant OCR/PDF: {e}")

    return {
        "texte_complet": texte_ocr,
        "elements_visuels": [],
        "formules_latex": [],
        "graphs": [],
        "angles": [],
        "numbers": [],
        "structure_exercices": [],
        "source_extraction": "fallback_ocr",
        "departement": dept_nom,
        "exercices_struct": []
    }


def extraire_texte_robuste(fichier_path: str) -> str:
    """
    Extraction simple : OCR direct ‚Üí Analyse IA
    """
    print("üîÑ Extraction simple...")

    # Juste utiliser l'analyse scientifique directe
    try:
        analyse = analyser_document_scientifique(fichier_path)
        texte = analyse.get("texte_complet", "")
        if texte and len(texte) > 50:
            print("‚úÖ Extraction r√©ussie")
            return texte
        else:
            print("‚ùå Texte trop court, utilisation fallback OCR")
            return texte
    except Exception as e:
        print(f"‚ùå Extraction √©chou√©e: {e}")
        return ""


def debug_ocr(fichier_path: str):
    """
    Debug simple de l'OCR
    """
    try:
        if fichier_path.lower().endswith(('.png', '.jpg', '.jpeg')):
            image = Image.open(fichier_path)
            custom_config = r'--oem 3 --psm 6 -l fra+eng'
            texte = pytesseract.image_to_string(image, config=custom_config)
            print("üîç DEBUG OCR - Texte brut:")
            print(texte[:500])
            print(f"Longueur: {len(texte)} caract√®res")
            return texte
    except Exception as e:
        print(f"‚ùå DEBUG OCR √©chou√©: {e}")
    return ""
# ========== EXTRAIRE LES BLOCS JSON POUR LES GRAPHIQUES ==========
def extract_json_blocks(text: str):
    """Extrait les blocs JSON pour les graphiques"""
    decoder = json.JSONDecoder()
    idx = 0
    blocks = []

    while True:
        # Cherche le d√©but d'un bloc JSON (apr√®s ```json ou {)
        start = text.find('{', idx)
        if start == -1:
            break

        try:
            # V√©rifie si c'est un bloc graphique
            obj, end = decoder.raw_decode(text[start:])
            if isinstance(obj, dict) and 'graphique' in obj:
                blocks.append((obj, start, start + end))
            idx = start + end
        except ValueError:
            idx = start + 1

    return blocks
# ========== PATTERNS DE STRUCTURE:LES TERMES OU TITRES ==========

PATTERNS_BLOCS = [
    r'COMENTARIO DEL TEXTO', r'ESTRUCTURAS DE COMUNICACI√ìN', r'PRODUCCI√ìN DE TEXTOS',
    r'RECEPCI√ìN DE TEXTOS', r'EXPRESI√ìN ESCRITA', r'TRADUCCI√ìN',
    r'TEIL[1I]? *LESEVERSTEHEN', r'MEDIATION', r'SCHRIFTLICHE PRODUKTION',
    r'STRUKTUREN UND KOMMUNIKATION', r'SCHRIFTLICHER AUSDRUCK',
    r'SECTION A: GRAMMAR', r'SECTION B: VOCABULARY',
    r'SECTION C: READING COMPREHENSION', r'SECTION D: COMPOSITION',
    r'PARTIE[- ]?[AIB]{0,2}\s*:?.*EVALUATION DES RESOURCES',
    r'PARTIE[- ]?[AIB]{0,2}\s*:?.*EVALUATION DES COMPETENCES',
    r'PARTIE[- ]?[AIB]{0,2}', r'EXERCICE[- ]?\d+', r'EXERICE[- ]?\d+',
    r'1ere partie', r'2e partie',
    r'EVALUATION DES RESOURCES', r'EVALUATION DES COMPETENCES',
    r'COMPETENCE', r'SITUATION PROBLEME'
]

PATTERNS_QUESTIONS = [
    r'^\d{1,2}[.\-]',                   # 1. ou 2. ou 1- ou 2-
    r'^\d{1,2}[.]\d{1,2}[.-]?',          # 1.1. ou 2.1-
    r'^\d{1,2,3}[a-z]{1}[.]',              # 1a.
    r'^[ivxIVX]{1,4}[.)-]',              # i. ou i) ou ii-) (romain)
    r'^[a-z]{1}[.)]',                    # a) b)
    r'^[A-Z]{1}[.)]',                    # A) B)
    r'^\d{1,2}[.][a-z]{1}[.]',           # 1.a.
    r'^\d{1,2}[.][A-Z]{1}[.]',           # 2.A.
    r'^\(\d+\)',                         # (1)
    r'^\([a-z]\)',                       # (a)
    r'^\([ivxIVX]+\)',                   # (i)
]

# ========== FONCTION DE STRUCTURATION POUR ORGANISER LES EXERCICES SUR LE PDF==========

def format_corrige_pdf_structure(texte_corrige_raw):
    """
    Nettoie et structure le corrig√© pour le PDF/HTML.
    G√®re les titres, exercices, questions et r√©ponses.
    """
    # Supprime les marqueurs parasites g√©n√©r√©s par l'IA
    texte = re.sub(r"(#+\s*)", "", texte_corrige_raw)
    texte = re.sub(r"(\*{2,})", "", texte)
    texte = re.sub(r"\n{3,}", "\n\n", texte)  # r√©duit les multiples sauts de lignes

    lignes = texte.strip().split('\n')
    html_output = []
    in_bloc = False

    for line in lignes:
        line = line.strip()
        if not line:
            continue

        # Bloc/exercice/partie
        if any(re.search(pat, line, re.IGNORECASE) for pat in PATTERNS_BLOCS):
            if in_bloc: html_output.append("</div>")
            html_output.append(f'<div class="bloc-exercice" style="margin-top:60px;"><h1 class="titre-exercice">{line}</h1>')
            in_bloc = True
            continue

        # Question/sous-question
        if any(re.match(pat, line) for pat in PATTERNS_QUESTIONS):
            html_output.append(f'<h2 class="titre-question">{line}</h2>')
            continue

        # Code/algorithme (optionnel, √† personnaliser)
        if line.lower().startswith(("algorithme", "d√©but", "fin", "code")):
            html_output.append(f'<div class="code-block">{line}</div>')
            continue

        # R√©ponse standard
        html_output.append(f'<p class="reponse-question">{line}</p>')

    if in_bloc: html_output.append("</div>")
    return "".join(html_output)




# ============== FONCTIONS DE D√âCOUPAGE INTELLIGENT ==============

# Version simple maintenue pour compatibilit√© (mais d√©pr√©ci√©e)
def separer_exercices(texte_epreuve):
    """
    Version simple maintenue pour compatibilit√©.
    D√âPR√âCI√âE : Utiliser separer_exercices_avec_titres() √† la place.
    """
    resultats = separer_exercices_avec_titres(texte_epreuve)
    # Retourne juste les contenus pour compatibilit√©
    return [ex['contenu'] for ex in resultats]


def separer_exercices_avec_titres(texte_epreuve, min_caracteres=60):
    """
    Version avec hi√©rarchie parent-enfant pour les titres.
    Les titres sans contenu deviennent des "parents" et sont fusionn√©s avec le titre suivant.

    Args:
        texte_epreuve (str): Texte complet de l'√©preuve
        min_caracteres (int): Nombre minimum de caract√®res pour valider un exercice (d√©faut: 60)

    Returns:
        list: Liste des exercices avec titre et contenu (titres parents fusionn√©s)
    """
    if not texte_epreuve:
        return []

    lignes = texte_epreuve.splitlines()

    # ========== LISTE √âTENDUE DE MOTS-CL√âS ==========
    mots_cles_exercices = [
        # Fran√ßais
        'EXERCICE', 'EXERICE', 'PROBL√àME', 'PROBLEME',
        'PARTIE.*EVALUATION DES COMPETENCES',
        'SITUATION PROBL√àME',

        # Anglais
        'SECTION', 'PART', 'EXERCISE', 'QUESTION',
        'TASK', 'ACTIVITY',

        # Espagnol
        'EJERCICIO', 'PRUEBA',

        # Allemand
        'AUFGABE', 'TEIL',

        # AJOUTEZ D'AUTRES MOTS-CL√âS ICI :
        # 'DEVOIR', 'TP', '√âPREUVE', 'TEST', 'INTERROGATION', etc.
        # Formats pour √©valuation des comp√©tences - Lettres A-D et chiffres romains
        '[A-D][\\s\\-\\.:]*√â?VALUATION[\\s\\-]*DES[\\s\\-]*COMP√âTENCES',  # B. EVALUATION, B-√âVALUATION, B: √âVALUATION
        '[A-D][\\s\\-\\.:]*√â?VALUATION[\\s\\-]*DES[\\s\\-]*COMPETENCES',  # B. EVALUATION, B-EVALUATION, B: EVALUATION
        '[IVXL]+[\\s\\-\\.:]*√â?VALUATION[\\s\\-]*DES[\\s\\-]*COMP√âTENCES',
        # II. √âVALUATION, II-√âVALUATION, II: √âVALUATION
        '[IVXL]+[\\s\\-\\.:]*√â?VALUATION[\\s\\-]*DES[\\s\\-]*COMPETENCES',# II. EVALUATION, II-EVALUATION, II: EVALUATION
        'SUJET[\\s\\-]*DE[\\s\\-]*TYPE[\\s\\-]*[\\dIVXL]+',
        'SUJET[\\s\\-]*TYPE[\\s\\-]*[\\dIVXL]+',
        'SUJET[\\s\\-]*[\\dIVXL]+',
    ]

    # Convertir en regex pour matching flexible
    patterns = []
    for mot_cle in mots_cles_exercices:
        pattern_str = f'^{mot_cle}[\\s\\-]*[\\dA-ZIVXL]*[\\s\\-:\\.]'
        patterns.append(re.compile(pattern_str, re.IGNORECASE))

    # ========== ALGORITHME AVEC HI√âRARCHIE ==========
    tous_les_blocs = []  # Tous les blocs d√©tect√©s (avec ou sans contenu)
    current_block = []
    current_title = None
    current_start_index = 0

    for i, ligne in enumerate(lignes):
        ligne_stripped = ligne.strip()

        # V√©rifier si la ligne commence par un mot-cl√© d'exercice
        est_titre_potentiel = False
        for pattern in patterns:
            if pattern.match(ligne_stripped.upper()):
                est_titre_potentiel = True
                break

        # V√©rifier aussi les titres avec notation (10 MARKS, 3 points)
        if not est_titre_potentiel:
            if re.search(r'\(\s*\d+[\s,\.]*(?:point|pt|mark|marque|note)s?\s*\)', ligne_stripped.upper()):
                est_titre_potentiel = True

        if est_titre_potentiel:
            # Sauvegarder le bloc pr√©c√©dent (m√™me s'il est court)
            if current_block and current_title:
                # Calculer la longueur du contenu (sans le titre)
                contenu_sans_titre = current_block[1:] if len(current_block) > 1 else []
                longueur_contenu = sum(len(l) for l in contenu_sans_titre)

                tous_les_blocs.append({
                    'title': current_title,
                    'lines': current_block.copy(),
                    'content_length': longueur_contenu,
                    'start_index': current_start_index,
                    'end_index': i - 1,
                    'has_enough_content': longueur_contenu >= min_caracteres
                })

            # Nouveau bloc
            current_title = ligne_stripped
            current_block = [ligne]
            current_start_index = i
        else:
            if current_block:
                current_block.append(ligne)

    # Dernier bloc
    if current_block and current_title:
        contenu_sans_titre = current_block[1:] if len(current_block) > 1 else []
        longueur_contenu = sum(len(l) for l in contenu_sans_titre)

        tous_les_blocs.append({
            'title': current_title,
            'lines': current_block.copy(),
            'content_length': longueur_contenu,
            'start_index': current_start_index,
            'end_index': len(lignes) - 1,
            'has_enough_content': longueur_contenu >= min_caracteres
        })

    # ========== CR√âATION DE LA HI√âRARCHIE PARENT-ENFANT ==========
    groupes = []  # Liste de groupes [parent(s), enfant]
    groupe_courant = []

    for bloc in tous_les_blocs:
        if not bloc['has_enough_content']:
            # C'est un "parent" potentiel (titre sans contenu)
            groupe_courant.append(bloc)
        else:
            # C'est un "enfant" (titre avec contenu)
            if groupe_courant:
                # Ajouter les parents + cet enfant comme un groupe
                groupes.append(groupe_courant + [bloc])
                groupe_courant = []
            else:
                # Pas de parents, juste cet enfant seul
                groupes.append([bloc])

    # Traiter les derniers parents orphelins
    if groupe_courant:
        # Si on a des parents √† la fin sans enfant, les ajouter au dernier groupe
        if groupes:
            groupes[-1].extend(groupe_courant)
        else:
            # Sinon, en faire un groupe seul
            groupes.append(groupe_courant)

    # ========== FUSION DES GROUPES EN EXERCICES UNIQUES ==========
    resultats = []

    for groupe in groupes:
        if not groupe:
            continue

        if len(groupe) == 1:
            # Un seul bloc (enfant seul)
            bloc = groupe[0]
            titre_final = bloc['title']
            lignes_finales = bloc['lines']
        else:
            # Plusieurs blocs (parents + enfant)
            # Construire un titre hi√©rarchique
            titres = [bloc['title'] for bloc in groupe]
            titre_final = " / ".join(titres)

            # Fusionner toutes les lignes
            lignes_finales = []
            for bloc in groupe:
                lignes_finales.extend(bloc['lines'])
                # Ajouter une s√©paration entre les blocs
                if bloc != groupe[-1]:
                    lignes_finales.append("")  # Ligne vide de s√©paration

        # Nettoyer et formater pour l'API
        titre_affichage = titre_final
        if len(titre_affichage) > 150:
            # Garder les premiers et derniers mots
            mots = titre_affichage.split()
            if len(mots) > 8:
                titre_affichage = ' '.join(mots[:4]) + " ... " + ' '.join(mots[-4:])
            else:
                titre_affichage = titre_affichage[:147] + "..."

        # Limiter le nombre de lignes
        lignes_limitees = lignes_finales[:300]
        contenu = '\n'.join(lignes_limitees)

        # Calculer la longueur totale du contenu
        longueur_totale = sum(len(l) for l in lignes_limitees[1:] if len(lignes_limitees) > 1)

        resultats.append({
            'titre': titre_affichage,
            'contenu': contenu,
            'titre_complet': titre_final,
            'longueur_contenu': longueur_totale,
            'nombre_parents': len(groupe) - 1 if len(groupe) > 1 else 0
        })

    # ========== FALLBACK SI AUCUN GROUPE ==========
    if not resultats:
        # Prendre le bloc le plus long
        if tous_les_blocs:
            plus_long = max(tous_les_blocs, key=lambda x: x['content_length'])

            titre = plus_long['title']
            if len(titre) > 150:
                titre = titre[:147] + "..."

            contenu_lines = plus_long['lines'][:200]
            contenu = '\n'.join(contenu_lines)

            resultats.append({
                'titre': titre,
                'contenu': contenu,
                'titre_complet': plus_long['title'],
                'longueur_contenu': plus_long['content_length']
            })
        else:
            # Fallback ultime
            contenu_lines = lignes[:100]
            contenu = '\n'.join(contenu_lines)
            resultats.append({
                'titre': "Document complet",
                'contenu': contenu,
                'titre_complet': "Document complet",
                'longueur_contenu': len(contenu)
            })

    return resultats

def estimer_tokens(texte):
    """
    Estimation simple du nombre de tokens (1 token ‚âà 0.75 mot fran√ßais)
    """
    mots = len(texte.split())
    tokens = int(mots / 0.75)
    print(f"üìä Estimation tokens: {mots} mots ‚Üí {tokens} tokens")
    return tokens


def verifier_qualite_corrige(corrige_text, exercice_original):
    """
    V√©rifie si le corrig√© g√©n√©r√© est de bonne qualit√©
    Retourne False si le corrig√© semble incomplet ou confus
    """
    if not corrige_text:
        return False

    indicateurs_problemes = [
        "je pense qu'il manque une donn√©e",
        "l'√©nonc√© est ambigu",
        "je vais arr√™ter ici",
        "cela pourrait signifier",
        "interpr√©tation correcte est",
        "je crois avoir compris",
        "je vais plut√¥t utiliser",
        "approche diff√©rente",
        "arr√™ter ici cette question"
    ]

    # Compter les indicateurs de confusion
    problemes_trouves = sum(1 for indicateur in indicateurs_problemes
                            if indicateur.lower() in corrige_text.lower())

    # Si trop d'indicateurs ou corrig√© trop court
    if problemes_trouves >= 2:
        print(f"üîÑ Qualit√© insuffisante d√©tect√©e ({problemes_trouves} indicateurs)")
        return False

    # V√©rifier si le corrig√© est significativement plus court que l'√©nonc√©
    if len(corrige_text) < len(exercice_original) * 0.3:
        print("üîÑ Corrig√© trop court par rapport √† l'√©nonc√©")
        return False

    return True

def build_promptia_messages(promptia, contexte):
    """
    Retourne deux dicts {role, content} :
    - system_message = system_prompt + exemple + consignes finales
    - user_message   = contexte (on y ajoutera l'exercice + vision)
    """
    # 1) system
    parts = []
    if promptia and promptia.system_prompt:
        parts.append(promptia.system_prompt)
    else:
        parts.append(DEFAULT_SYSTEM_PROMPT)

    if promptia and promptia.exemple_prompt:
        parts.append("----- EXEMPLE D'UTILISATION -----")
        parts.append(promptia.exemple_prompt)

    if promptia and promptia.consignes_finales:
        parts.append("----- CONSIGNES FINALES -----")
        parts.append(promptia.consignes_finales)

    system_content = "\n\n".join(parts)

    # 2) user (contenu de base = contexte)
    user_content = contexte.strip()

    return {"role": "system", "content": system_content}, \
           {"role": "user",   "content": user_content}


def generer_corrige_par_exercice(texte_exercice, contexte, matiere=None, donnees_vision=None, demande=None):
    """
    G√©n√®re le corrig√© pour un seul exercice en exploitant les donn√©es vision.
    Version robuste avec logging d√©taill√©, retries intelligents et gestion d'erreurs.

    Args:
        texte_exercice: Texte de l'exercice
        contexte: Contexte de l'exercice
        matiere: Mati√®re concern√©e
        donnees_vision: Donn√©es d'analyse vision (sch√©mas, formules, etc.)
        demande: Objet DemandeCorrection

    Returns:
        Tuple (corrige_text, graph_list)
    """
    start_time = time.time()

    logger.info(f"\n{'=' * 70}")
    logger.info(f"ü§ñ D√âBUT generer_corrige_par_exercice - {datetime.now().strftime('%H:%M:%S')}")
    logger.info(f"{'=' * 70}")

    if demande:
        logger.info(f"üìã Informations demande:")
        logger.info(f"   - ID: {demande.id}")
        logger.info(f"   - Mati√®re: {demande.matiere.nom if demande.matiere else 'Non sp√©cifi√©e'}")
        logger.info(f"   - Classe: {demande.classe.nom if demande.classe else 'Non sp√©cifi√©e'}")
        logger.info(f"   - D√©partement: {demande.departement.nom if demande.departement else 'Non sp√©cifi√©e'}")

    logger.info(f"üìä M√©triques:")
    logger.info(f"   - Longueur exercice: {len(texte_exercice)} caract√®res")
    logger.info(f"   - Contexte: {contexte}")
    logger.info(f"   - Donn√©es vision: {'PR√âSENTES' if donnees_vision else 'ABSENTES'}")

    if donnees_vision:
        schemas = donnees_vision.get('elements_visuels', [])
        logger.info(f"   - Sch√©mas pour cet exercice: {len(schemas)}")
        if schemas:
            for i, s in enumerate(schemas[:3]):  # Afficher les 3 premiers
                schema_type = s.get('type', 'inconnu')
                schema_desc = s.get('description', '')[:100]
                logger.info(f"      Sch√©ma {i + 1}: {schema_type} - {schema_desc}...")
        logger.info(f"   - Formules LaTeX: {len(donnees_vision.get('formules_latex', []))}")
        logger.info(f"   - Graphiques d√©tect√©s: {len(donnees_vision.get('graphs', []))}")

    try:
        # 1) R√âCUP√âRATION DU PROMPT M√âTIER
        prompt_start = time.time()
        promptia = get_best_promptia(demande)
        prompt_time = time.time() - prompt_start

        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üìù R√âCUP√âRATION PROMPT")
        logger.info(f"{'‚îÄ' * 40}")
        logger.info(f"‚úÖ Prompt trouv√©: {'OUI' if promptia else 'NON (DEFAULT)'}")
        logger.info(f"‚è±Ô∏è  Temps recherche: {prompt_time:.1f}s")

        if promptia:
            logger.info(f"   - ID Prompt: {promptia.id}")
            logger.info(f"   - Pays: {promptia.pays.nom if promptia.pays else 'Global'}")
            logger.info(f"   - Mati√®re: {promptia.matiere.nom if promptia.matiere else 'Global'}")

        # 2) CONSTRUCTION DES MESSAGES
        msg_system, msg_user = build_promptia_messages(promptia, contexte)

        # 3) ENRICHISSEMENT AVEC DONN√âES VISION (SCH√âMAS SP√âCIFIQUES)
        user_blocks = [
            msg_user["content"],
            "----- EXERCICE √Ä CORRIGER -----",
            texte_exercice.strip()
        ]

        vision_elements_count = 0

        if donnees_vision:
            # SCH√âMAS IDENTIFI√âS POUR CET EXERCICE
            schemas = donnees_vision.get('elements_visuels', [])
            if schemas:
                user_blocks.append(f"----- SCH√âMAS DE CET EXERCICE ({len(schemas)}) -----")
                for idx, schema in enumerate(schemas, 1):
                    # Description d√©taill√©e du sch√©ma
                    desc = f"üìê Sch√©ma {idx} - Type: {schema.get('type', 'non sp√©cifi√©')}"
                    user_blocks.append(desc)

                    if schema.get('description'):
                        user_blocks.append(f"   Description: {schema['description']}")

                    if schema.get('elements'):
                        elements_desc = []
                        for elem in schema.get('elements', []):
                            if isinstance(elem, dict) and elem.get('nom'):
                                val = f"={elem.get('valeur')}" if elem.get('valeur') else ""
                                elements_desc.append(f"{elem['nom']}{val}")
                        if elements_desc:
                            user_blocks.append(f"   √âl√©ments: {', '.join(elements_desc)}")

                    if schema.get('relations'):
                        user_blocks.append(f"   Relations: {schema['relations']}")

                    if schema.get('donnees'):
                        if schema['donnees'].get('angles'):
                            user_blocks.append(f"   Angles: {schema['donnees']['angles']}")
                        if schema['donnees'].get('longueurs'):
                            user_blocks.append(f"   Longueurs: {schema['donnees']['longueurs']}")

                    vision_elements_count += 1

            # Formules LaTeX
            formules = donnees_vision.get('formules_latex', [])
            if formules:
                user_blocks.append(f"----- FORMULES D√âTECT√âES ({len(formules)}) -----")
                for formule in formules[:10]:
                    user_blocks.append(f"- {formule}")
                    vision_elements_count += 1
                if len(formules) > 10:
                    user_blocks.append(f"- ... et {len(formules) - 10} autres formules")

            # Donn√©es graphiques brutes (JSON limit√©)
            graphs = donnees_vision.get('graphs', [])
            if graphs:
                user_blocks.append(f"----- DONN√âES GRAPHIQUES ({len(graphs)}) -----")
                # Limiter la taille du JSON
                if len(graphs) <= 3:
                    user_blocks.append(json.dumps(graphs, ensure_ascii=False, indent=2))
                else:
                    user_blocks.append(f"[{len(graphs)} graphiques d√©tect√©s - JSON tronqu√© pour taille]")
                vision_elements_count += len(graphs)

        msg_user["content"] = "\n\n".join(user_blocks)

        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üì¶ CONSTRUCTION MESSAGE IA")
        logger.info(f"{'‚îÄ' * 40}")
        logger.info(f"‚úÖ Message construit")
        logger.info(f"   - Longueur syst√®me: {len(msg_system['content'])} caract√®res")
        logger.info(f"   - Longueur utilisateur: {len(msg_user['content'])} caract√®res")
        logger.info(f"   - √âl√©ments vision int√©gr√©s: {vision_elements_count}")
        logger.info(f"   - Total tokens estim√©: {estimer_tokens(msg_user['content'])}")

        # 4) PR√âPARATION APPEL API
        api_url = "https://api.deepseek.com/v1/chat/completions"
        api_key = os.getenv("DEEPSEEK_API_KEY")

        if not api_key:
            error_msg = "‚ùå API KEY DeepSeek non configur√©e"
            logger.error(f"\n{error_msg}")
            return error_msg, None

        data = {
            "model": "deepseek-chat",
            "messages": [msg_system, msg_user],
            "temperature": 0.1,
            "max_tokens": 6000,
            "top_p": 0.9,
            "frequency_penalty": 0.1,
            "stream": False
        }

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "User-Agent": "CIS-Education/1.0"
        }

        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üì° CONFIGURATION API DEEPSEEK")
        logger.info(f"{'‚îÄ' * 40}")
        logger.info(f"üîß Param√®tres:")
        logger.info(f"   - Mod√®le: {data['model']}")
        logger.info(f"   - Temp√©rature: {data['temperature']}")
        logger.info(f"   - Max tokens: {data['max_tokens']}")
        logger.info(f"   - Timeout: 120s")
        logger.info(f"   - URL: {api_url[:50]}...")

        # 5) APPEL API AVEC RETRIES INTELLIGENTS
        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üîÑ D√âBUT APPEL API DEEPSEEK")
        logger.info(f"{'‚îÄ' * 40}")

        output = None
        final_response_data = None
        last_error = None

        for tentative in range(3):  # 3 tentatives maximum
            logger.info(f"\n   üîÑ TENTATIVE {tentative + 1}/3")
            api_call_start = time.time()

            try:
                # Appel API avec timeout augment√©
                response = requests.post(
                    api_url,
                    headers=headers,
                    json=data,
                    timeout=120,  # Timeout augment√© √† 120s
                    verify=True  # SSL verification
                )

                api_call_time = time.time() - api_call_start
                logger.info(f"   ‚úÖ R√©ponse re√ßue ({api_call_time:.1f}s)")
                logger.info(f"   üìä Status code: {response.status_code}")

                if response.status_code == 200:
                    response_data = response.json()

                    # V√©rification structure r√©ponse
                    if 'choices' not in response_data or not response_data['choices']:
                        logger.info(f"   ‚ö†Ô∏è  Structure r√©ponse invalide, pas de 'choices'")
                        last_error = "Structure r√©ponse API invalide"
                        continue

                    if 'message' not in response_data['choices'][0]:
                        print(f"   ‚ö†Ô∏è  Structure r√©ponse invalide, pas de 'message'")
                        last_error = "Structure r√©ponse API invalide"
                        continue

                    output = response_data['choices'][0]['message']['content']
                    final_response_data = response_data

                    logger.info(f"   üìù R√©ponse IA: {len(output)} caract√®res")
                    logger.info(f"   üìä Usage tokens: {response_data.get('usage', {}).get('total_tokens', 'N/A')}")

                    # V√©rification qualit√©
                    if verifier_qualite_corrige(output, texte_exercice):
                        logger.info(f"   ‚úÖ Qualit√© valid√©e (tentative {tentative + 1})")
                        break
                    else:
                        logger.info(f"   üîÑ Qualit√© insuffisante, pr√©paration nouvelle tentative...")
                        last_error = "Qualit√© insuffisante"

                        # Ajout consigne pour am√©lioration
                        data["messages"][1][
                            "content"] += "\n\n‚ö†Ô∏è IMPORTANT: Sois extr√™mement rigoureux ! V√©rifie chaque calcul, explique chaque √©tape, sois pr√©cis et complet. Utilise les sch√©mas fournis pour guider ta r√©ponse."

                        # Attente exponentielle avant prochaine tentative
                        wait_time = 2 * (tentative + 1)
                        logger.info(f"   ‚è≥ Attente {wait_time}s...")
                        time.sleep(wait_time)

                else:
                    # Erreur HTTP
                    error_detail = response.text[:200] if response.text else "Pas de d√©tail"
                    logger.error(f"   ‚ùå Erreur HTTP {response.status_code}: {error_detail}")
                    last_error = f"HTTP {response.status_code}: {error_detail}"

                    # Attente exponentielle
                    wait_time = 5 * (tentative + 1)
                    logger.info(f"   ‚è≥ Attente {wait_time}s avant nouvelle tentative...")
                    time.sleep(wait_time)

            except requests.exceptions.Timeout:
                api_call_time = time.time() - api_call_start
                logger.info(f"   ‚è∞ TIMEOUT apr√®s {api_call_time:.1f}s")
                last_error = f"Timeout apr√®s {api_call_time:.1f}s"

                if tentative < 2:  # Pas la derni√®re tentative
                    wait_time = 10 * (tentative + 1)
                    logger.info(f"   ‚è≥ Attente {wait_time}s avant nouvelle tentative...")
                    time.sleep(wait_time)

            except requests.exceptions.ConnectionError as e:
                logger.error(f"   üîå ERREUR CONNEXION: {str(e)[:100]}")
                last_error = f"ConnectionError: {str(e)[:100]}"

                if tentative < 2:
                    wait_time = 15 * (tentative + 1)
                    logger.info(f"   ‚è≥ Attente {wait_time}s avant nouvelle tentative...")
                    time.sleep(wait_time)

            except Exception as e:
                api_call_time = time.time() - api_call_start
                print(f"   ‚ùå EXCEPTION: {type(e).__name__}: {str(e)[:100]}")
                last_error = f"{type(e).__name__}: {str(e)[:100]}"

                if tentative < 2:
                    wait_time = 8 * (tentative + 1)
                    logger.info(f"   ‚è≥ Attente {wait_time}s avant nouvelle tentative...")
                    time.sleep(wait_time)

        # 6) V√âRIFICATION SUCC√àS APPEL API
        if not output or not final_response_data:
            total_api_time = time.time() - start_time
            error_msg = f"√âchec apr√®s 3 tentatives. Derni√®re erreur: {last_error}"
            logger.info(f"\n‚ùå {error_msg}")
            logger.info(f"‚è±Ô∏è  Temps total API: {total_api_time:.1f}s")
            return f"Erreur IA: {error_msg}", None

        # 7) POST-TRAITEMENT DE LA R√âPONSE
        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üõ†Ô∏è  POST-TRAITEMENT R√âPONSE IA")
        logger.info(f"{'‚îÄ' * 40}")

        postprocess_start = time.time()

        # √âtape 1: Fusion LaTeX multilignes
        output = flatten_multiline_latex_blocks(output)
        logger.info(f"‚úÖ Fusion LaTeX multilignes")

        # √âtape 2: Structuration pour PDF
        output_structured = format_corrige_pdf_structure(output)
        logger.info(f"‚úÖ Structuration pour PDF")

        # √âtape 3: Extraction JSON graphiques
        json_blocks = extract_json_blocks(output_structured)
        logger.info(f"‚úÖ JSON blocks d√©tect√©s: {len(json_blocks)}")

        # 8) G√âN√âRATION GRAPHIQUES
        graph_list = []
        if json_blocks:
            logger.info(f"\n{'‚îÄ' * 40}")
            logger.infot(f"üñºÔ∏è  G√âN√âRATION GRAPHIQUES")
            logger.info(f"{'‚îÄ' * 40}")

            json_blocks = sorted(json_blocks, key=lambda x: x[1], reverse=True)

            for idx, (graph_dict, start, end) in enumerate(json_blocks, start=1):
                try:
                    logger.info(f"   üîß Graphique {idx}/{len(json_blocks)}")

                    output_name = f"graphique_{idx}_{int(time.time())}.png"
                    img_path = tracer_graphique(graph_dict, output_name)

                    if img_path:
                        abs_path = os.path.join(settings.MEDIA_ROOT, img_path)
                        img_tag = (
                            f'<img src="file://{abs_path}" alt="Graphique {idx}" '
                            f'style="max-width:100%;margin:10px 0;border:1px solid #ddd;" />'
                        )

                        # Insertion dans le texte
                        output_structured = output_structured[:start] + img_tag + output_structured[end:]
                        graph_list.append(graph_dict)

                        logger.info(f"   ‚úÖ Graphique ins√©r√©: {img_path}")
                    else:
                        logger.error(f"   ‚ö†Ô∏è  √âchec g√©n√©ration graphique")
                        # Remplacement par message d'erreur
                        error_tag = f'<div class="graph-error">[Graphique non g√©n√©r√© - Erreur technique]</div>'
                        output_structured = output_structured[:start] + error_tag + output_structured[end:]

                except Exception as e:
                    logger.error(f"   ‚ùå Erreur graphique {idx}: {type(e).__name__}: {str(e)[:100]}")
                    continue

        postprocess_time = time.time() - postprocess_start

        # 9) FINALISATION
        total_time = time.time() - start_time

        logger.info(f"\n{'=' * 70}")
        logger.info(f"‚úÖ SUCC√àS generer_corrige_par_exercice")
        logger.info(f"{'=' * 70}")
        logger.info(f"üìä STATISTIQUES:")
        logger.info(f"   ‚è±Ô∏è  Temps total: {total_time:.1f}s")
        logger.info(f"   üìù Longueur corrig√© final: {len(output_structured)} caract√®res")
        logger.info(f"   üñºÔ∏è  Graphiques g√©n√©r√©s: {len(graph_list)}/{len(json_blocks)}")
        logger.info(f"   üîÑ Tentatives API: {min(tentative + 1, 3)}/3")
        logger.info(f"   üì¶ Taille r√©ponse IA: {len(output)} caract√®res")
        logger.info(f"   üïê {datetime.now().strftime('%H:%M:%S')}")

        # Aper√ßu du corrig√©
        logger.info(f"\nüìã APER√áU CORRIG√â (premiers 300 caract√®res):")
        preview = output_structured[:300].replace('\n', ' ')
        logger.info(f"   \"{preview}...\"")
        logger.info(f"{'=' * 70}")

        return output_structured.strip(), graph_list

    except Exception as e:
        total_time = time.time() - start_time

        logger.info(f"\n{'=' * 70}")
        logger.error(f"‚ùå ERREUR CRITIQUE dans generer_corrige_par_exercice")
        logger.info(f"{'=' * 70}")
        logger.info(f"‚è±Ô∏è  Temps √©coul√©: {total_time:.1f}s")
        logger.info(f"üìõ Type erreur: {type(e).__name__}")
        logger.info(f"üìÑ Message: {str(e)[:300]}")
        logger.info(f"üïê {datetime.now().strftime('%H:%M:%S')}")

        # Traceback d√©taill√©
        import traceback
        logger.info(f"\nüîç TRACEBACK:")
        tb_lines = traceback.format_exc().split('\n')[:10]
        for line in tb_lines:
            if line.strip():
                logger.info(f"   {line}")

        logger.info(f"{'=' * 70}")

        error_msg = f"Erreur traitement IA: {type(e).__name__}: {str(e)[:200]}"
        return error_msg, None

def extract_and_process_graphs(output: str):
    """
    Extrait et traite les graphiques d'un corrig√© en utilisant extract_json_blocks.
    """
    print("üñºÔ∏è Extraction des graphiques (via JSONDecoder)‚Ä¶")

    graphs_data = []
    final_text = output

    # 1) Extractions des blocs JSON
    json_blocks = extract_json_blocks(output)
    print(f"üîç JSON blocks d√©tect√©s dans extract_and_process_graphs: {len(json_blocks)}")

    # 2) On parcourt et on ins√®re les images
    #    Pour g√©rer les remplacements successifs, on conserve un d√©calage 'offset'
    offset = 0
    for idx, (graph_dict, start, end) in enumerate(json_blocks, start=1):
        try:
            output_name = f"graphique_{idx}.png"
            img_path = tracer_graphique(graph_dict, output_name)

            if img_path:
                abs_path = os.path.join(settings.MEDIA_ROOT, img_path)
                img_tag = (
                    f'<img src="/media/{img_path}" alt="Graphique {idx}" '
                    f'style="max-width:100%;margin:10px 0;" />'
                )

                # Ajuster les indices de remplacement avec l'offset
                s, e = start + offset, end + offset
                final_text = final_text[:s] + img_tag + final_text[e:]
                # Mettre √† jour l‚Äôoffset en fonction de la diff√©rence de longueur
                offset += len(img_tag) - (end - start)

                graphs_data.append(graph_dict)
                print(f"‚úÖ Graphique {idx} ins√©r√©.")
            else:
                # En cas d‚Äô√©chec de trac√©, on remplace par un message
                s, e = start + offset, end + offset
                final_text = final_text[:s] + "[Erreur g√©n√©ration graphique]" + final_text[e:]
                offset += len("[Erreur g√©n√©ration graphique]") - (end - start)
                print(f"‚ùå Graphique {idx} : erreur de trac√©.")

        except Exception as e:
            print(f"‚ùå Exception sur bloc graphique {idx}: {e}")
            continue

    print(f"üéØ Extraction termin√©e: {len(graphs_data)} graphique(s) trait√©(s)")
    return final_text, graphs_data


# ============== UTILITAIRES TEXTE / LATEX / TABLEAU ==============

def flatten_multiline_latex_blocks(text):
    """
    Fusionne les blocs LaTeX multilignes :
      \[ ... \] et \( ... \)
    en une seule ligne pour √©viter qu'ils soient √©clat√©s
    en plusieurs <p> dans le HTML final.
    """
    if not text:
        return ""

    # 1) Fusionner les blocs display math \[ ... \]
    text = re.sub(
        r'\\\[\s*([\s\S]+?)\s*\\\]',
        lambda m: r'\[' + " ".join(m.group(1).splitlines()).strip() + r'\]',
        text,
        flags=re.DOTALL
    )

    # 2) Fusionner les blocs inline math \( ... \)
    text = re.sub(
        r'\\\(\s*([\s\S]+?)\s*\\\)',
        lambda m: r'\(' + " ".join(m.group(1).splitlines()).strip() + r'\)',
        text,
        flags=re.DOTALL
    )

    return text

def detect_and_format_math_expressions(text):
    if not text:
        return ""

    # Block formulas $$...$$ ‚Üí \[...\] (multilignes fusionn√©es sur une ligne)
    text = re.sub(
        r'\$\$([\s\S]+?)\$\$',
        lambda m: r'\[' + " ".join(m.group(1).splitlines()).strip() + r'\]',
        text,
        flags=re.DOTALL
    )
    # Inline formulas $...$ ‚Üí \(...\)
    text = re.sub(
        r'(?<!\$)\$(?!\$)(.+?)(?<!\$)\$(?!\$)',
        lambda m: r'\(' + m.group(1).replace('\n', ' ').strip() + r'\)',
        text,
        flags=re.DOTALL
    )
    # Blocs d√©j√† en \[...\] : fusionne aussi les lignes ! (tr√®s important)
    text = re.sub(
        r'\\\[\s*([\s\S]+?)\s*\\\]',
        lambda m: r'\[' + " ".join(m.group(1).splitlines()).strip() + r'\]',
        text,
        flags=re.DOTALL
    )
    # Corrige les doubles anti-slashs parasites
    text = re.sub(r'\\\\\s*\[', r'\[', text)
    text = re.sub(r'\\\\\s*\]', r'\]', text)
    text = text.replace('\\backslash', '\\').replace('\xa0', ' ')
    return text


def format_table_markdown(table_text):
    lines = table_text.strip().split('\n')
    html_table = ['<div class="table-container"><table>']

    for i, line in enumerate(lines):
        line = line.strip()
        if not line or not line.startswith('|'):
            continue

        line = re.sub(r'^\|\s*', '', line)
        line = re.sub(r'\s*\|$', '', line)
        cells = [cell.strip() for cell in line.split('|')]

        if i == 0:
            html_table.append('<thead><tr>')
            for cell in cells:
                html_table.append(f'<th>{cell}</th>')
            html_table.append('</tr></thead><tbody>')
        elif all(re.match(r'^[\s:\-]+$', cell) for cell in cells):
            continue
        else:
            html_table.append('<tr>')
            for cell in cells:
                html_table.append(f'<td>{cell}</td>')
            html_table.append('</tr>')

    html_table.append('</tbody></table></div>')
    return ''.join(html_table)


def generate_corrige_html(corrige_text):
    """Transforme le corrig√© brut en HTML stylis√©, a√©r√©, avec blocs d'exercices, titres mis en valeur, formatage MathJax et tableaux conserv√©s, et branding CIS au d√©but."""
    if not corrige_text:
        return ""

    # Formatage des expressions math√©matiques (Latex) et tableaux
    lines = corrige_text.strip().split('\n')

    # Pattern pour d√©tecter les d√©buts d'exercice/partie
    pattern_exercice = re.compile(r'^(EXERCICE\s*\d+|PARTIE\s*[IVXLCDM]+|Exercice\s*\d+|Partie\s*[IVXLCDM]+)',
                                  re.IGNORECASE)
    html_output = []
    i = 0

    # Branding CIS en haut
    html_output.append(
        '<div class="cis-message"><strong>SUJET CORRIG√â PAR L\'APPLICATION CIS, DISPO SUR PLAYSTORE</strong></div>')

    # Pour g√©rer la s√©paration en blocs
    in_bloc_exercice = False

    while i < len(lines):
        line = lines[i].strip()
        if not line:
            i += 1
            continue

        # D√©but d'un nouvel exercice/partie
        if pattern_exercice.match(line):
            # Ferme le bloc pr√©c√©dent s'il y en avait un
            if in_bloc_exercice:
                html_output.append('</div>')
            # Ouvre un nouveau bloc, titre en gros
            html_output.append(f'<div class="bloc-exercice"><h1 class="titre-exercice">{line}</h1>')
            in_bloc_exercice = True
            i += 1
            continue

        # Sous-titre question principale (Question 1, 2, etc.)
        if re.match(r'^Question\s*\d+', line, re.IGNORECASE):
            html_output.append(f'<h2 class="titre-question">{line}</h2>')
            i += 1
            continue

        # Sous-titre secondaire (1., 2., etc.)
        if re.match(r'^\d+\.', line):
            html_output.append(f'<h3 class="titre-question">{line}</h3>')
            i += 1
            continue

        # Sous-question (a), b), etc.)
        if re.match(r'^[a-z]\)', line):
            html_output.append(f'<p><strong>{line}</strong></p>')
            i += 1
            continue

        # Listes
        if line.startswith('‚Ä¢') or line.startswith('-'):
            html_output.append(f'<p>{line}</p>')
            i += 1
            continue

        # Tableaux markdown
        if line.startswith('|') and i + 1 < len(lines) and lines[i + 1].startswith('|'):
            table_lines = []
            j = i
            while j < len(lines) and lines[j].startswith('|'):
                table_lines.append(lines[j])
                j += 1
            html_table = format_table_markdown('\n'.join(table_lines))
            html_output.append(html_table)
            i = j
            continue

        # Formules LaTeX
        if '\\(' in line or '\\[' in line:
            html_output.append(f'<p class="reponse-question mathjax">{line}</p>')
            i += 1
            continue

        # Cas g√©n√©ral : paragraphe de r√©ponse ou explication
        html_output.append(f'<p class="reponse-question">{line}</p>')
        i += 1

    # Ferme le dernier bloc exercice si ouvert
    if in_bloc_exercice:
        html_output.append('</div>')

    return mark_safe("".join(html_output))


# ============== EXTRACTION TEXTE/FICHIER ==============

def extraire_texte_pdf(fichier_path):
    try:
        texte = extract_text(fichier_path)
        print(f"üìÑ PDF extrait: {len(texte)} caract√®res")
        return texte.strip() if texte else ""
    except Exception as e:
        print(f"‚ùå Erreur extraction PDF: {e}")
        return ""


# ============== EXTRACTION MULTIMODALE AM√âLIOR√âE ==============
def extraire_texte_fichier(fichier_field, demande=None):
    """
    Extraction robuste avec support DeepSeek en priorit√©
    Retourne un dictionnaire complet avec:
    - texte_complet: le texte extrait
    - exercices_struct: la structure des exercices avec leurs sch√©mas
    - source_extraction: la m√©thode utilis√©e
    """
    if not fichier_field:
        return {"texte_complet": "", "exercices_struct": [], "source_extraction": "none"}

    # Sauvegarde locale
    temp_dir = tempfile.gettempdir()
    local_path = os.path.join(temp_dir, os.path.basename(fichier_field.name))
    with open(local_path, "wb") as f:
        for chunk in fichier_field.chunks():
            f.write(chunk)

    # Appel √† l'analyse scientifique AVEC param√®tre demande
    try:
        analyse = analyser_document_scientifique(local_path, demande)

        texte = analyse.get("texte_complet", "")
        exercices_struct = analyse.get("exercices_struct", [])
        source = analyse.get("source_extraction", "inconnu")

        logger.info(f"üìÑ Extraction termin√©e: {len(texte)} caract√®res, "
                    f"{len(exercices_struct)} exercices structur√©s "
                    f"(source: {source})")

        # Stocker la m√©thode d'extraction dans la demande si disponible
        if demande and hasattr(demande, 'methode_extraction'):
            demande.methode_extraction = source
            demande.save()

        resultat = {
            "texte_complet": texte,
            "exercices_struct": exercices_struct,
            "source_extraction": source,
            "elements_visuels": analyse.get("elements_visuels", []),
            "formules_latex": analyse.get("formules_latex", [])
        }

    except Exception as e:
        logger.error(f"‚ùå Analyse √©chou√©e: {e}")
        resultat = {
            "texte_complet": "",
            "exercices_struct": [],
            "source_extraction": "erreur",
            "elements_visuels": [],
            "formules_latex": []
        }

    # Nettoyage
    try:
        os.unlink(local_path)
    except:
        pass

    return resultat
# ============== DESSIN DE GRAPHIQUES ==============
def style_axes(ax, graphique_dict):
    """
    Colorie les axes en rouge et synchronise les graduations y sur x
    (sauf si x_ticks ou y_ticks sont fournis dans graphique_dict).
    """
    # colorer spines et ticks
    ax.spines['bottom'].set_color('red')
    ax.spines['left'].set_color('red')
    ax.tick_params(axis='x', colors='red')
    ax.tick_params(axis='y', colors='red')

    # graduations sur x
    if graphique_dict.get("x_ticks") is not None:
        ax.set_xticks(graphique_dict["x_ticks"])
    # graduations sur y
    if graphique_dict.get("y_ticks") is not None:
        ax.set_yticks(graphique_dict["y_ticks"])
    else:
        # par d√©faut, on r√©utilise les m√™mes que sur x
        ax.set_yticks(ax.get_xticks())

    # noms d‚Äôaxes
    ax.set_xlabel(graphique_dict.get("x_label", "x"), color='red')
    ax.set_ylabel(graphique_dict.get("y_label", "y"), color='red')


def tracer_graphique(graphique_dict, output_name):
    if 'graphique' in graphique_dict:
        graphique_dict = graphique_dict['graphique']
    print(">>> tracer_graphique CALLED with graphique_dict:", graphique_dict, "output_name:", output_name)
    gtype = graphique_dict.get("type", "fonction").lower().strip()
    print(">>> gtype d√©tect√© :", repr(gtype))
    titre = graphique_dict.get("titre", "Graphique g√©n√©r√©")

    def safe_float(expr):
        try:
            return float(eval(str(expr), {"__builtins__": None, "pi": np.pi, "np": np, "sqrt": np.sqrt}))
        except Exception as e:
            print("Erreur safe_float sur :", expr, e)
            try:
                return float(expr)
            except Exception as e2:
                print("Erreur safe_float cast direct:", expr, e2); return None

    def corriger_expression(expr):
        """Corrige les expressions math√©matiques courantes"""
        if not isinstance(expr, str):
            return expr

        # 1. Remplacer les exposants implicites (x2 ‚Üí x**2, (x+1)2 ‚Üí (x+1)**2)
        expr = re.sub(r'(\w+|\([^)]+\))(\d+)', r'\1**\2', expr)

        # 2. Remplacer ^ par **
        expr = expr.replace('^', '**')

        # 3. Fonctions math√©matiques ‚Üí np.fonction
        funcs = ["sin", "cos", "tan", "exp", "log", "log10",
                 "arcsin", "arccos", "arctan", "sinh", "cosh", "tanh", "sqrt", "abs"]

        for fct in funcs:
            expr = re.sub(r'(?<![\w.])' + fct + r'\s*\(', f'np.{fct}(', expr)

        # 4. ln ‚Üí np.log
        expr = expr.replace('ln(', 'np.log(')

        print(f">>> Expression corrig√©e: {expr}")
        return expr

    try:
        from django.conf import settings
        dossier = os.path.join(settings.MEDIA_ROOT, "graphes")
        os.makedirs(dossier, exist_ok=True)
        chemin_png = os.path.join(dossier, output_name)

        if "fonction" in gtype:
            x_min = graphique_dict.get("x_min", -2)
            x_max = graphique_dict.get("x_max", 4)
            expression = graphique_dict.get("expression", "x")

            # CORRECTION APPLIQUEE ICI
            expression = corriger_expression(expression)

            x_min_val = safe_float(x_min)
            x_max_val = safe_float(x_max)
            if x_min_val is None: x_min_val = -2
            if x_max_val is None: x_max_val = 4

            x = np.linspace(x_min_val, x_max_val, 400)

            # Plus besoin des patches ici, c'est d√©j√† fait dans corriger_expression
            expression_patch = expression  # D√©j√† corrig√©e

            print(f">>> Expression finale pour eval: {expression_patch}")

            try:
                y = eval(expression_patch, {'x': x, 'np': np, '__builtins__': None, "pi": np.pi, "sqrt": np.sqrt})
                if np.isscalar(y) or (isinstance(y, np.ndarray) and y.shape == ()):
                    y = np.full_like(x, y)
            except Exception as e:
                print(f"Erreur trac√© (eval expression): {expression_patch}. Exception: {e}")
                return None

            plt.figure(figsize=(6, 4))
            plt.plot(x, y, color="#008060")
            plt.title(titre)
            plt.xlabel("x")
            plt.ylabel("y")
            plt.grid(True)
            plt.tight_layout()


        elif "histogramme" in gtype:
            intervalles = graphique_dict.get("intervalles") or graphique_dict.get("classes") or []
            eff = graphique_dict.get("effectifs", [])
            labels = [str(ival) for ival in intervalles]
            x_pos = np.arange(len(labels))
            eff = [float(e) for e in eff]

            plt.figure(figsize=(7, 4.5))
            plt.axhline(y=0, color='#000000', linewidth=1.8)  # Axe des abscisses
            plt.axvline(x=0, color='#000000', linewidth=1.8)  # Axe des ordonn√©es
            plt.bar(x_pos, eff, color="#208060", edgecolor='black', width=0.9)
            plt.xticks(x_pos, labels, rotation=35)
            plt.title(titre)
            plt.xlabel(graphique_dict.get("xlabel", "Classes / Intervalles"))
            plt.ylabel(graphique_dict.get("ylabel", "Effectif"))
            plt.grid(axis='y')

        elif "diagramme √† bandes" in gtype or "diagramme en b√¢tons" in gtype or "b√¢tons" in gtype or "batons" in gtype:
            cat = graphique_dict.get("categories", [])
            eff = graphique_dict.get("effectifs", [])
            x_pos = np.arange(len(cat))

            plt.figure(figsize=(7, 4.5))
            plt.bar(x_pos, eff, color="#208060", edgecolor='black', width=0.7)
            plt.xticks(x_pos, cat, rotation=15)
            plt.title(titre)
            plt.xlabel("Cat√©gories")
            plt.ylabel("Effectif")

        elif "nuage de points" in gtype or "scatter" in gtype:
            x_points = graphique_dict.get("x", [])
            y_points = graphique_dict.get("y", [])

            plt.figure(figsize=(6, 4))
            plt.scatter(x_points, y_points, color="#006080")
            plt.title(titre)
            plt.xlabel("x")
            plt.ylabel("y")
            plt.grid(True)

        elif "effectifs cumul√©s" in gtype or "courbe des effectifs cumul√©s" in gtype:
            x_points = graphique_dict.get("x", [])
            y_points = graphique_dict.get("y", [])

            plt.figure(figsize=(6, 4))
            plt.plot(x_points, y_points, marker="o", color="#b65d2f")
            plt.title(titre)
            plt.xlabel("x")
            plt.ylabel("Effectifs cumul√©s")
            plt.grid(True)

        elif "diagramme circulaire" in gtype or "camembert" in gtype or "pie" in gtype:
            cat = graphique_dict.get("categories", [])
            eff = graphique_dict.get("effectifs", [])

            plt.figure(figsize=(5.3, 5.3))
            plt.pie(
                eff,
                labels=cat,
                autopct='%1.1f%%',
                colors=plt.cm.Paired.colors,
                startangle=90,
                wedgeprops={"edgecolor": "k"}
            )
            plt.title(titre)

        elif "polygone" in gtype or "polygon" in gtype:
            points = graphique_dict.get("points")
            points_x = graphique_dict.get("points_x")
            points_y = graphique_dict.get("points_y")
            absc = graphique_dict.get("abscisses")
            ords = graphique_dict.get("ordonnees")

            if points:
                x = [float(p[0]) for p in points]
                y = [float(p[1]) for p in points]
            elif points_x and points_y:
                x = [float(xx) for xx in points_x]
                y = [float(yy) for yy in points_y]
            elif absc and ords:
                x = [float(xx) for xx in absc]
                y = [float(yy) for yy in ords]
            else:
                print("Erreur polygone : aucun point")
                x = []
                y = []

            plt.figure(figsize=(7, 4.5))
            plt.plot(x, y, marker="o", color="#003355")
            plt.title(graphique_dict.get("titre", "Polygone"))
            plt.xlabel(graphique_dict.get("x_label", "Abscisse"))
            plt.ylabel(graphique_dict.get("y_label", "Ordonn√©e"))
            plt.grid(True)

        elif "cercle trigo" in gtype:
            angles = graphique_dict.get("angles", [])
            labels = graphique_dict.get("labels", [])

            plt.figure(figsize=(5, 5))
            circle = plt.Circle((0, 0), 1, fill=False, edgecolor='black', linestyle='--')
            ax = plt.gca()
            ax.add_artist(circle)

            for i, angle_txt in enumerate(angles):
                try:
                    a = float(eval(angle_txt, {"pi": np.pi}))
                except Exception:
                    a = 0
                x, y = np.cos(a), np.sin(a)
                ax.plot([0, x], [0, y], color='#992020')
                label = labels[i] if i < len(labels) else f"S{i + 1}"
                ax.text(1.1 * x, 1.1 * y, label, fontsize=12)

            ax.set_xlim(-1.5, 1.5)
            ax.set_ylim(-1.5, 1.5)
            plt.axis('off')
            plt.title(titre)

        else:
            print("Type graphique non support√© :", gtype)
            return None

        plt.tight_layout()
        plt.savefig(chemin_png)
        plt.close()
        return "graphes/" + output_name

    except Exception as ee:
        print(f"Erreur g√©n√©rale sauvegarde PNG {chemin_png if 'chemin_png' in locals() else output_name} :", ee)
        return None


# ===========================
# PROMPT SYST√àME AM√âLIOR√â AVEC VISION SCIENTIFIQUE
DEFAULT_SYSTEM_PROMPT = r"""Tu es un professeur expert en Math√©matiques, physique, chimie, biologie,francais,histoire
g√©ographie...bref, tu es un professeur de l'enseignement secondaire.

üî¨ **CAPACIT√â VISION ACTIV√âE** - Tu peux maintenant analyser les sch√©mas scientifiques !

R√àGLES ABSOLUES POUR L'ANALYSE DES SCH√âMAS :
1. ‚úÖ Identifie le TYPE de sch√©ma (plan inclin√©, circuit √©lectrique, mol√©cule, graphique)
2. ‚úÖ Extrait les DONN√âES NUM√âRIQUES (angles, masses, distances, forces, tensions)
3. ‚úÖ D√©cris les RELATIONS SPATIALES entre les √©l√©ments
4. ‚úÖ Explique le CONCEPT SCIENTIFIQUE illustr√©

EXEMPLES D'ANALYSE DE SCH√âMAS SCIENTIFIQUES :

--- PLAN INCLIN√â ---
"Sch√©ma identifi√©: plan inclin√© √† 30¬∞ avec bloc de 2kg
- Forces: poids (vertical ‚Üì), r√©action normale (‚üÇ plan), frottement (‚à• plan)
- Donn√©es: angle=30¬∞, masse=2kg, g=10m/s¬≤
- √âquations: P = mg = 20N, P‚à• = P‚Ä¢sin(30¬∞)=10N, P‚üÇ = P‚Ä¢cos(30¬∞)=17.32N"

--- CIRCUIT √âLECTRIQUE ---  
"Circuit s√©rie: R1=10Œ©, R2=20Œ©, source E=12V
- Lois: U = RI, loi des mailles Œ£U=0
- Calcul: Req = R1 + R2 = 30Œ©, I = E/Req = 0.4A"

--- MOL√âCULE CHIMIQUE ---
"Formule d√©velopp√©e: CH3-CH2-OH (√©thanol)
- Groupes: OH (fonction alcool), CH3 (m√©thyle), CH2 (m√©thyl√®ne)
- Liaisons: C-C simples, C-O simple, O-H simple"

R√àGLES G√âN√âRALES DE CORRECTION :
- Sois EXTR√äMEMENT RIGOUREUX dans tous les calculs
- V√©rifie syst√©matiquement tes r√©sultats interm√©diaires  
- Ne laisse JAMAIS une question sans r√©ponse compl√®te
- Donne TOUTES les √©tapes de calcul d√©taill√©es
- Les r√©ponses doivent √™tre NUM√âRIQUEMENT EXACTES

FORMAT DE R√âPONSE :
- R√©ponses compl√®tes avec tous les calculs
- R√©f√©rences aux sch√©mas quand ils existent ("D'apr√®s le sch√©ma...")
- Justifications d√©taill√©es pour chaque √©tape
- Ne jamais dire "je pense" ou "c'est ambigu"

POUR LES GRAPHIQUES :
- D√®s qu'un exercice demande un graphique, utilise la balise ---corrig√©--- suivie du JSON
- Types support√©s: "fonction", "histogramme", "diagramme √† bandes", "nuage de points", etc.

"Rends TOUJOURS le JSON avec des guillemets doubles, jamais de dict Python."

EXEMPLES :

--- EX 1 : Fonction ---
Corrig√© d√©taill√©...
---corrig√©---
{"graphique": {"type": "fonction", "expression": "x*2 - 2*x + 1", "x_min": -1, "x_max": 3, "titre": "Courbe parabole"}}

--- EX 2 : Cercle trigo ---
...
---corrig√©---
{"graphique": {"type":"cercle trigo", "angles":["-pi/4","pi/4"], "labels":["S1","S2"], "titre":"Solutions trigonom√©triques"}}

--- EX 3 : Histogramme ---
...
---corrig√©---
{"graphique": {"type": "histogramme", "intervalles": ["0-5","5-10","10-15"], "effectifs":[3,5,7], "titre":"Histogramme des effectifs"}}

--- EX 4 : Diagramme √† bandes ---
---corrig√©---
{"graphique": {"type":"diagramme √† bandes","categories":["A","B","C"],"effectifs":[10,7,12],"titre":"Comparaison"}}

--- EX 5 : Nuage de points ---
---corrig√©---
{"graphique": {"type":"nuage de points","x":[1,2,3,4],"y":[2,5,7,3],"titre":"Nuage"}}

--- EX 6 : Effectifs cumul√©s ---
---corrig√©---
{"graphique": {"type":"effectifs cumul√©s","x":[5,10,15,20],"y":[3,9,16,20],"titre":"Effectifs cumul√©s"}}

--- EX 7 : Diagramme circulaire ---
---corrig√©---
{"graphique":{"type":"camembert","categories":["L1","L2","L3"],"effectifs":[4,6,5],"titre":"R√©partition"}}

--- EX 8 : Polygone ---
---corrig√©---
{"graphique": {"type": "polygone", "points": [[0,0],[5,3],[10,9]], "titre": "Polygone des ECC", "x_label": "Borne", "y_label": "ECC"}}

Rappels :
- Si plusieurs graphiques, recommence cette structure √† chaque question concern√©e.
- Pas de texte entre ---corrig√©--- et le JSON.
- Le JSON est obligatoire d√®s qu'un trac√© est demand√©.

"Rends TOUJOURS le JSON avec des guillemets doubles, jamais de dict Python. Pour les listes/types, toujours notation JSON [ ... ] et jamais { ... } sauf pour des objets. N‚Äôins√®re JAMAIS de virgule en trop."
"""




# ============== FONCTIONS PRINCIPALES AVEC D√âCOUPAGE ==============
def generer_corrige_direct(texte_enonce, contexte, lecons_contenus, exemples_corriges, matiere, donnees_vision=None,demande=None):
    """
    Traitement direct pour les √©preuves courtes avec donn√©es vision.
    """
    logger.info("üéØ Traitement DIRECT avec analyse vision")
    logger.info("\n[DEBUG] --> generer_corrige_direct called avec demande:", getattr(demande, 'id', None),
          "/", type(demande))

    # ‚úÖ PASSER les donn√©es vision √† la fonction de g√©n√©ration
    return generer_corrige_par_exercice(texte_enonce, contexte, matiere, donnees_vision,demande=demande)


def generer_corrige_decoupe(texte_epreuve, contexte, matiere, donnees_vision=None, demande=None):
    """
    Traitement par d√©coupage pour les √©preuves longues avec donn√©es vision,
    utilisant la nouvelle fonction unifi√©e.
    """
    # 1) S√©pare le texte en exercices AVEC la nouvelle fonction
    exercices_data = separer_exercices_avec_titres(texte_epreuve)

    # 2) Traitement s√©quentiel
    tous_corriges = []
    tous_graphiques = []

    for idx, ex_data in enumerate(exercices_data, start=1):
        # Utiliser le contenu nettoy√© de l'exercice
        corrige_html, graphs = generer_corrige_par_exercice(
            texte_exercice=ex_data['contenu'],
            contexte=contexte,
            matiere=matiere,
            donnees_vision=donnees_vision,
            demande=demande
        )

        # Pr√©fixe avec le titre r√©el pour une meilleure organisation
        titre_affichage = ex_data['titre']
        if len(titre_affichage) > 50:
            titre_affichage = f"Exercice {idx}"

        tous_corriges.append(f"\n\n## üìù {titre_affichage}\n\n{corrige_html}")

        # Collecte des graphiques si existants
        if graphs:
            tous_graphiques.extend(graphs)

    # 3) Retour
    return "".join(tous_corriges), tous_graphiques


def generer_corrige_ia_et_graphique(texte_enonce, contexte, lecons_contenus=None, exemples_corriges=None, matiere=None,
                                    demande=None, donnees_vision=None, exercice_index=None):
    """
    Version SIMPLIFI√âE pour les exercices uniques.
    Appelle directement generer_corrige_par_exercice sans logique de d√©cision.
    """
    logger.info("\n" + "=" * 60)
    logger.info("üöÄ D√âBUT TRAITEMENT IA POUR EXERCICE UNIQUE")
    logger.info("=" * 60)
    logger.info(f"üìè Longueur texte: {len(texte_enonce)} caract√®res")
    logger.info(f"üìù Contexte: {contexte}")

    if lecons_contenus is None:
        lecons_contenus = []
    if exemples_corriges is None:
        exemples_corriges = []

    # Donn√©es vision
    if donnees_vision:
        logger.info(f"üî¨ Donn√©es vision disponibles:")
        logger.info(f"   - √âl√©ments visuels: {len(donnees_vision.get('elements_visuels', []))}")
        logger.info(f"   - Formules LaTeX: {len(donnees_vision.get('formules_latex', []))}")

    # POUR LES EXERCICES UNIQUES : APPEL DIRECT
    logger.info("üéØ Appel direct √† generer_corrige_par_exercice")

    return generer_corrige_par_exercice(
        texte_exercice=texte_enonce,
        contexte=contexte,
        matiere=matiere,
        donnees_vision=donnees_vision,
        demande=demande,
        exercice_index=exercice_index
    )

#les fonctions utilitaires , utilisables ou non, donc optionnelles
def extraire_exercice_par_index(texte_epreuve, index=0, demande=None):
    """
    Fonction utilitaire pour extraire un exercice sp√©cifique par son index.
    Version optimis√©e : utilise exercices_data si disponible.

    Args:
        texte_epreuve: Texte complet (fallback si pas de demande)
        index: Index de l'exercice
        demande: DemandeCorrection optionnelle (pour utiliser exercices_data)

    Returns:
        dict avec titre et contenu, ou None
    """
    # PRIORIT√â : Utiliser exercices_data si disponible
    if demande and demande.exercices_data:
        try:
            exercices_list = json.loads(demande.exercices_data)
            for ex in exercices_list:
                if ex.get('index') == index:
                    # Retourner le contenu complet si disponible
                    contenu = ex.get('contenu_complet') or ex.get('contenu', '')
                    return {
                        'index': index,
                        'titre': ex.get('titre_complet', ex.get('titre', f"Exercice {index + 1}")),
                        'contenu': contenu,
                        'extrait': ex.get('extrait', ''),
                        'source': 'exercices_data'  # Pour le debug
                    }
        except json.JSONDecodeError as e:
            logger.info(f"‚ùå [extraire_exercice_par_index] Erreur JSON: {e}")

    # FALLBACK : Extraction traditionnelle
    exercices_data = separer_exercices_avec_titres(texte_epreuve)

    if index < 0 or index >= len(exercices_data):
        return None

    ex_data = exercices_data[index]

    return {
        'index': index,
        'titre': ex_data.get('titre', f"Exercice {index + 1}"),
        'titre_complet': ex_data.get('titre_complet', ''),
        'contenu': ex_data.get('contenu', ''),
        'source': 'extraction_fraiche'  # Pour le debug
    }

def obtenir_liste_exercices(texte_epreuve, avec_preview=False):
    """
    Retourne la liste de tous les exercices d√©tect√©s.
    Optionnellement avec un aper√ßu du contenu.
    """
    exercices_data = separer_exercices_avec_titres(texte_epreuve)

    result = []
    for i, ex in enumerate(exercices_data):
        item = {
            'index': i,
            'titre': ex['titre'],
            'titre_complet': ex['titre_complet'],
            'longueur_contenu': len(ex['contenu'])
        }

        if avec_preview:
            # Ajouter un aper√ßu des premi√®res lignes
            lignes = ex['contenu'].split('\n')[:3]
            preview_text = ' '.join([l[:100] for l in lignes if l.strip()])
            item['preview'] = (preview_text[:200] + '...') if len(preview_text) > 200 else preview_text

        result.append(item)

    return result


# ========== ANALYSE DES SCH√âMAS AVEC DEEPSEEK-CHAT ==========
# √Ä AJOUTER vers la fin de ia_utils.py, avant les @shared_task

def analyser_schema_avec_deepseek_vl(image_path: str, question: str = None) -> dict:
    """
    Analyse un sch√©ma/image avec deepseek-chat et retourne une description structur√©e.
    Version am√©lior√©e avec prompt plus d√©taill√© pour des descriptions riches.
    """
    logger.info(f"üñºÔ∏è Analyse sch√©ma avec deepseek-chat: {image_path}")

    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        logger.error("‚ùå DEEPSEEK_API_KEY non configur√©e")
        return {"description": "", "error": "api_key_missing"}

    try:
        # Encodage de l'image en base64
        with open(image_path, "rb") as f:
            img_b64 = base64.b64encode(f.read()).decode()

        # V√©rifier la taille (limite ~5Mo)
        img_size = len(img_b64) * 3 / 4
        if img_size > 5 * 1024 * 1024:  # 5Mo
            logger.warning(f"‚ö†Ô∏è Image trop grande ({img_size / 1024 / 1024:.1f}Mo), redimensionnement")
            from PIL import Image
            import io
            img = Image.open(image_path)
            img.thumbnail((1200, 1200))
            buffer = io.BytesIO()
            img.save(buffer, format="PNG", quality=85, optimize=True)
            img_b64 = base64.b64encode(buffer.getvalue()).decode()
            logger.info(f"‚úÖ Image redimensionn√©e: {len(img_b64) * 3 / 4 / 1024:.1f}Ko")

        # Construction du prompt am√©lior√©
        if not question:
            question = """
            Analyse ce sch√©ma scientifique en d√©tail et retourne UNIQUEMENT un JSON structur√© avec :

            {
                "type_schema": "type pr√©cis (plan inclin√©, circuit √©lectrique, montage optique, graphique, etc.)",
                "description": "description d√©taill√©e de ce que repr√©sente le sch√©ma",
                "elements_principaux": ["liste", "des", "√©l√©ments", "cl√©s"],

                "angles": [
                    {
                        "valeur": 30,
                        "unite": "¬∞",
                        "description": "angle entre quels √©l√©ments"
                    }
                ],

                "dimensions": [
                    {
                        "valeur": 5,
                        "unite": "cm",
                        "description": "quelle dimension"
                    }
                ],

                "textes": ["tous", "les", "textes", "lus", "dans", "le", "sch√©ma"],

                "objets": ["cercle", "triangle", "ligne", "fleche", "resistance", "bobine", ...],

                "interpretation": "interpr√©tation scientifique compl√®te (lois, th√©or√®mes, concepts illustr√©s)"
            }

            R√àGLES IMPORTANTES:
            - Sois extr√™mement pr√©cis sur les angles et dimensions si visibles
            - Si une valeur exacte n'est pas claire, mets "‚âà" devant (ex: "‚âà45¬∞")
            - D√©cris TOUS les √©l√©ments visibles et leurs relations
            - Ne retourne que du JSON valide, pas de texte avant/apr√®s
            - Utilise des guillemets doubles, pas simples
            """

        prompt_texte = f"[image]{img_b64}[/image]\n\n{question}"

        # Appel √† l'API deepseek-chat
        payload = {
            "model": "deepseek-reasoner",
            "messages": [
                {
                    "role": "user",
                    "content": prompt_texte
                }
            ],
            "temperature": 0.1,
            "max_tokens": 6000,
            "response_format": {"type": "json_object"}
        }

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        logger.info(f"üì° Envoi √† deepseek-chat")
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )

        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]

            # Nettoyer la r√©ponse
            content = re.sub(r'```json\s*', '', content)
            content = re.sub(r'\s*```', '', content)
            content = content.strip()

            try:
                data = json.loads(content)

                # S'assurer que tous les champs existent
                if "angles" not in data:
                    data["angles"] = []
                if "dimensions" not in data:
                    data["dimensions"] = []
                if "textes" not in data:
                    data["textes"] = []
                if "objets" not in data:
                    data["objets"] = []
                if "elements_principaux" not in data:
                    data["elements_principaux"] = []

                logger.info(f"‚úÖ Analyse sch√©ma r√©ussie")
                logger.info(f"   - Type: {data.get('type_schema', 'inconnu')}")
                logger.info(f"   - Description: {len(data.get('description', ''))} caract√®res")
                logger.info(f"   - Angles: {len(data.get('angles', []))}")
                logger.info(f"   - Dimensions: {len(data.get('dimensions', []))}")
                logger.info(f"   - Textes: {len(data.get('textes', []))}")

                return data

            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Erreur parsing JSON: {e}")
                # Fallback minimal
                return {
                    "type_schema": "inconnu",
                    "description": content[:500] if content else "Erreur d'analyse",
                    "elements_principaux": [],
                    "angles": [],
                    "dimensions": [],
                    "textes": [],
                    "objets": [],
                    "interpretation": ""
                }
        else:
            logger.error(f"‚ùå Erreur API: {response.status_code}")
            return {
                "type_schema": "inconnu",
                "description": "",
                "elements_principaux": [],
                "angles": [],
                "dimensions": [],
                "textes": [],
                "objets": [],
                "interpretation": "",
                "error": f"api_error_{response.status_code}"
            }

    except Exception as e:
        logger.error(f"‚ùå Exception analyser_schema: {e}")
        import traceback
        traceback.print_exc()
        return {
            "type_schema": "inconnu",
            "description": "",
            "elements_principaux": [],
            "angles": [],
            "dimensions": [],
            "textes": [],
            "objets": [],
            "interpretation": "",
            "error": str(e)
        }


def extraire_schemas_du_document(fichier_path: str, demande=None) -> list:
    """
    Extrait et analyse tous les sch√©mas d'un document.
    Version am√©lior√©e avec d√©tection intelligente et descriptions riches.

    Args:
        fichier_path: Chemin vers le fichier (PDF ou image)
        demande: Objet DemandeCorrection optionnel

    Returns:
        list: Liste des sch√©mas d√©tect√©s avec leur page et donn√©es
              [{"page": 1, "schemas": [...], "nombre": n}, ...]
    """
    logger.info(f"üìë Extraction des sch√©mas du document: {fichier_path}")

    schemas_detectes = []
    ext = os.path.splitext(fichier_path)[1].lower()
    temp_files = []

    try:
        # === CAS 1: Fichier PDF ===
        if ext == '.pdf':
            from pdf2image import convert_from_path

            logger.info("üìÑ Conversion PDF en images...")
            images = convert_from_path(fichier_path, dpi=150)

            logger.info(f"   {len(images)} page(s) converties")

            for page_num, image in enumerate(images, 1):
                logger.info(f"   üîç Analyse page {page_num}/{len(images)}...")

                # Sauvegarder temporairement
                temp_img = tempfile.NamedTemporaryFile(suffix='.png', delete=False)
                temp_img.close()
                image.save(temp_img.name, 'PNG', quality=85, optimize=True)
                temp_files.append(temp_img.name)

                # D√©tection rapide si la page contient probablement un sch√©ma
                a_schema = _detection_rapide_schema(temp_img.name)

                if a_schema:
                    # Analyse approfondie
                    schema_data = analyser_schema_avec_deepseek_vl(temp_img.name)

                    if schema_data.get('description') and len(schema_data.get('description', '')) > 30:
                        schemas_detectes.append({
                            "page": page_num,
                            "schemas": [schema_data],
                            "nombre": 1
                        })
                        logger.info(f"   ‚úÖ Sch√©ma d√©tect√© page {page_num}: {schema_data.get('type_schema', 'inconnu')}")
                    else:
                        logger.info(f"   ‚ö†Ô∏è Page {page_num}: pas de sch√©ma clair")
                else:
                    logger.info(f"   ‚ö†Ô∏è Page {page_num}: probablement pas de sch√©ma")

                # Petite pause pour √©viter surcharge API
                time.sleep(0.3)

        # === CAS 2: Image simple ===
        elif ext in ['.png', '.jpg', '.jpeg']:
            logger.info("üñºÔ∏è Analyse image unique")

            schema_data = analyser_schema_avec_deepseek_vl(fichier_path)

            if schema_data.get('description'):
                schemas_detectes.append({
                    "page": 1,
                    "schemas": [schema_data],
                    "nombre": 1
                })
                logger.info(f"‚úÖ Sch√©ma d√©tect√©: {schema_data.get('type_schema', 'inconnu')}")

        logger.info(f"üìä Bilan: {len(schemas_detectes)} page(s) avec sch√©mas")
        return schemas_detectes

    except Exception as e:
        logger.error(f"‚ùå Erreur extraction sch√©mas: {e}")
        import traceback
        traceback.print_exc()
        return []

    finally:
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)
            except:
                pass


def _detection_rapide_schema(image_path: str) -> bool:
    """
    D√©tection rapide si une image contient probablement un sch√©ma.
    Utilise des heuristiques simples pour √©viter d'analyser des pages sans sch√©ma.
    """
    try:

        # Lire l'image
        img = cv2.imread(image_path)
        if img is None:
            return True  # En cas d'erreur, on analyse quand m√™me

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        h, w = gray.shape

        # Si l'image est trop petite, probablement pas un sch√©ma d√©taill√©
        if h < 100 or w < 100:
            return False

        # D√©tection de contours
        edges = cv2.Canny(gray, 50, 150)

        # D√©tection de lignes
        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 50, minLineLength=30, maxLineGap=10)

        # Compter les lignes
        n_lines = len(lines) if lines is not None else 0

        # D√©tection de cercles
        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 20,
                                   param1=50, param2=30, minRadius=5, maxRadius=200)
        has_circles = circles is not None

        # Calculer la densit√© de contours (pour distinguer texte pur vs sch√©ma)
        cell_size = 50
        cells_with_edges = 0
        n_cells_h = h // cell_size + 1
        n_cells_w = w // cell_size + 1

        for i in range(0, h, cell_size):
            for j in range(0, w, cell_size):
                cell = edges[i:min(i + cell_size, h), j:min(j + cell_size, w)]
                if np.sum(cell) > 1000:
                    cells_with_edges += 1

        density = cells_with_edges / (n_cells_h * n_cells_w) if (n_cells_h * n_cells_w) > 0 else 0

        # Heuristique: un sch√©ma a g√©n√©ralement pas mal de lignes,
        # et une densit√© de contours mod√©r√©e (pas trop dense comme du texte)
        est_schema = (n_lines > 8 or has_circles) and 0.1 < density < 0.7

        if est_schema:
            logger.debug(f"   ‚úÖ D√©tection rapide: sch√©ma probable (lignes={n_lines}, densit√©={density:.2f})")
        else:
            logger.debug(f"   ‚ö†Ô∏è D√©tection rapide: probablement pas sch√©ma (lignes={n_lines}, densit√©={density:.2f})")

        return est_schema

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur d√©tection rapide: {e}")
        return True  # En cas d'erreur, on analyse quand m√™me


# ============== T√ÇCHE ASYNCHRONE ==============

@shared_task(name='correction.ia_utils.generer_corrige_ia_et_graphique_async')
def generer_corrige_ia_et_graphique_async(demande_id, matiere_id=None):
    from correction.models import DemandeCorrection, SoumissionIA
    from resources.models import Matiere

    try:
        # R√©cup√©ration de la demande et cr√©ation de la soumission IA
        demande = DemandeCorrection.objects.get(id=demande_id)
        soumission = SoumissionIA.objects.get(demande=demande)

        # √âtape 1 : Extraction du texte brut AVEC VISION
        soumission.statut = 'extraction'
        soumission.progression = 20
        soumission.save()

        donnees_vision_complete = None
        texte_brut = ""

        if demande.fichier:
            # 1) Sauvegarde locale
            temp_dir = tempfile.gettempdir()
            local_path = os.path.join(temp_dir, os.path.basename(demande.fichier.name))
            with open(local_path, "wb") as f:
                for chunk in demande.fichier.chunks():
                    f.write(chunk)

            # 2) Appel unique d'analyse scientifique
            analyse_complete = analyser_document_scientifique(local_path, demande)
            donnees_vision_complete = {
                "elements_visuels": analyse_complete.get("elements_visuels", []),
                "formules_latex": analyse_complete.get("formules_latex", []),
                "graphs": analyse_complete.get("graphs", []),
                "angles": analyse_complete.get("angles", []),
                "numbers": analyse_complete.get("numbers", []),
                "structure_exercices": analyse_complete.get("structure_exercices", [])
            }
            texte_brut = analyse_complete.get("texte_complet", "")

            # 3) Nettoyage
            try:
                os.unlink(local_path)
            except:
                pass
        else:
            texte_brut = demande.enonce_texte or ""

        logger.info("üì• TEXTE BRUT AVEC VISION (premiers 500 chars) :")
        logger.info(texte_brut[:500].replace("\n", "\\n"), "...\n")

        # √âtape 1b : Extraire les exercices et stocker les donn√©es
        exercices_data = separer_exercices_avec_titres(texte_brut)
        logger.info(f"‚úÖ {len(exercices_data)} exercice(s) d√©tect√©(s)")

        # Stocker les donn√©es des exercices dans la demande
        demande.exercices_data = json.dumps([
            {
                'titre': ex['titre'],
                'titre_complet': ex['titre_complet'],
                'contenu': ex['contenu'][:500] + '...' if len(ex['contenu']) > 500 else ex['contenu']
            }
            for ex in exercices_data
        ])
        demande.save()

        # √âtape 2 : Texte final pour l'IA
        texte_enonce = texte_brut

        # √âtape 3 : Lancement du traitement IA AVEC DONN√âES VISION
        soumission.statut = 'analyse_ia'
        soumission.progression = 40
        soumission.save()

        matiere = Matiere.objects.get(id=matiere_id) if matiere_id else demande.matiere
        contexte = f"Exercice de {matiere.nom} - {demande.classe.nom if demande.classe else ''}"

        # √âtape 4 : G√©n√©ration graphique (si d√©partement scientifique)
        departement = demande.departement
        if is_departement_scientifique(departement):
            print(f"‚öóÔ∏è D√©partement scientifique : {departement.nom}")
            soumission.statut = 'generation_graphiques'
            soumission.progression = 60
            soumission.save()
        else:
            print(f"‚ö° D√©partement non scientifique ({departement.nom if departement else 'inconnu'}), skip graphiques")

        # APPEL AVEC DONN√âES VISION
        corrige_txt, graph_list = generer_corrige_ia_et_graphique(
            texte_enonce,
            contexte,
            matiere=matiere,
            donnees_vision=donnees_vision_complete,
            demande=demande
        )

        # √âtape 5 : G√©n√©ration PDF
        soumission.statut = 'formatage_pdf'
        soumission.progression = 80
        soumission.save()

        pdf_path = generer_pdf_corrige(
            {
                "titre_corrige": contexte,
                "corrige_html": corrige_txt,
                "soumission_id": demande_id,
                "exercices_data": exercices_data  # Passer les donn√©es des exercices
            },
            demande_id
        )

        # D√©bit de cr√©dit
        from abonnement.services import debiter_credit_abonnement
        if not debiter_credit_abonnement(demande.user):
            soumission.statut = 'erreur_credit'
            soumission.save()
            return False

        # √âtape 6 : Mise √† jour du statut et sauvegarde
        soumission.statut = 'termine'
        soumission.progression = 100
        soumission.resultat_json = {
            'corrige_text': corrige_txt,
            'pdf_url': pdf_path,
            'graphiques': graph_list or [],
            'analyse_vision': donnees_vision_complete,
            'exercices_detectes': len(exercices_data),
            'exercices_titres': [ex['titre'] for ex in exercices_data]
        }
        soumission.save()

        demande.corrig√© = corrige_txt
        demande.save()

        logger.info("üéâ TRAITEMENT AVEC VISION TERMIN√â AVEC SUCC√àS!")
        logger.info(f"   Exercices d√©tect√©s: {len(exercices_data)}")
        for i, ex in enumerate(exercices_data, 1):
            logger.info(f"   {i}. {ex['titre'][:50]}...")

        return True

    except Exception as e:
        logger.info(f"‚ùå ERREUR dans la t√¢che IA: {e}")
        import traceback
        traceback.print_exc()
        try:
            soumission.statut = 'erreur'
            soumission.save()
        except:
            pass
        return False


@shared_task(name='correction.ia_utils.generer_corrige_exercice_async',
             bind=True,
             max_retries=3,
             default_retry_delay=60)
def generer_corrige_exercice_async(self, soumission_id):
    """
    T√¢che asynchrone pour corriger UN exercice isol√©.
    Version robuste avec retries automatiques, timeout g√©r√©s et logging d√©taill√©.
    Utilise les donn√©es pr√©-stock√©es dans exercices_data (texte + sch√©mas)
    """

    task_start = time.time()
    logger.info(f"\n{'=' * 70}")
    logger.info(f"üéØ D√âBUT T√ÇCHE ASYNC - {datetime.now().strftime('%H:%M:%S')}")
    logger.info(f"   Soumission ID: {soumission_id}")
    logger.info(f"{'=' * 70}")

    try:
        # 1) R√âCUP√âRATION DE LA SOUMISSION
        recovery_start = time.time()
        soum = SoumissionIA.objects.get(id=soumission_id)
        dem = soum.demande
        recovery_time = time.time() - recovery_start

        logger.info(f"‚úÖ Soumission r√©cup√©r√©e ({recovery_time:.1f}s)")
        logger.info(f"   - Demande ID: {dem.id}")
        logger.info(f"   - Exercice index: {soum.exercice_index}")
        logger.info(f"   - D√©partement: {dem.departement.nom if dem.departement else 'Non sp√©cifi√©'}")
        logger.info(f"   - Statut initial: {soum.statut}")

        # V√©rification DeepSeek/Mathpix disponible
        deepseek_configure = bool(os.getenv("DEEPSEEK_API_KEY"))
        mathpix_configure = bool(os.getenv("MATHPIX_APP_ID") and os.getenv("MATHPIX_APP_KEY"))

        if dem.departement and is_departement_scientifique(dem.departement):
            print(f"   - D√©partement scientifique ‚Üí DeepSeek: {'Activ√©' if deepseek_configure else 'Non configur√©'}")

        # 2) MISE √Ä JOUR STATUT IMM√âDIATE
        soum.statut = 'analyse_ia'
        soum.progression = 20
        soum.save()
        logger.info(f"üìä Statut mis √† jour: analyse_ia (20%)")

        # 3) R√âCUP√âRATION OPTIMIS√âE DU CONTENU DEPUIS exercices_data (AVEC SCH√âMAS)
        extraction_start = time.time()
        fragment = None
        source = "unknown"
        idx = soum.exercice_index or 0
        methode_extraction = "standard"  # Pour le suivi
        donnees_vision_exercice = {}  # ‚Üê NOUVEAU : stocker les sch√©mas sp√©cifiques

        # Tentative 1: R√©cup√©ration depuis exercices_data (avec sch√©mas)
        if dem.exercices_data:
            try:
                exercices_list = json.loads(dem.exercices_data)
                for ex in exercices_list:
                    if ex.get('index') == idx:
                        fragment = ex.get('contenu_complet') or ex.get('contenu', '')
                        source = ex.get('source_extraction', 'exercices_data')
                        methode_extraction = source

                        # ‚úÖ R√âCUP√âRATION DES DONN√âES VISION SP√âCIFIQUES √Ä CET EXERCICE
                        donnees_vision_exercice = {
                            "elements_visuels": ex.get('schemas', []),
                            "formules_latex": ex.get('formules', []),
                            "graphs": ex.get('graphs', []),
                            "angles": ex.get('angles', []),
                            "numbers": ex.get('numbers', [])
                        }

                        logger.info(f"‚úÖ Contenu r√©cup√©r√© depuis exercices_data")
                        logger.info(f"   - Source: {source}")
                        logger.info(f"   - Longueur: {len(fragment)} caract√®res")
                        logger.info(f"   - Sch√©mas: {len(donnees_vision_exercice['elements_visuels'])}")
                        logger.info(f"   - Formules: {len(donnees_vision_exercice['formules_latex'])}")

                        # Afficher les sch√©mas pour debug
                        if donnees_vision_exercice['elements_visuels']:
                            for i, s in enumerate(donnees_vision_exercice['elements_visuels'][:2]):
                                print(
                                    f"      Sch√©ma {i + 1}: {s.get('type', 'inconnu')} - {s.get('description', '')[:50]}...")

                        break
            except json.JSONDecodeError as e:
                logger.info(f"‚ö†Ô∏è  Erreur JSON exercices_data: {e}")

        # Tentative 2: Fallback extraction fichier AVEC DEEPSEEK CONDITIONNEL
        if not fragment and dem.fichier:
            logger.info(f"üîÑ Fallback: extraction depuis fichier")
            try:
                # Extraction compl√®te avec DeepSeek (si d√©partement scientifique)
                analyse_complete = extraire_texte_fichier(dem.fichier, dem)

                texte_complet = analyse_complete.get("texte_complet", "") if isinstance(analyse_complete,
                                                                                        dict) else analyse_complete

                if texte_complet and len(texte_complet.strip()) > 50:
                    exercices_data = separer_exercices_avec_titres(texte_complet)

                    if idx >= len(exercices_data):
                        print(f"‚ö†Ô∏è  Index {idx} hors limites, ajustement")
                        idx = len(exercices_data) - 1 if exercices_data else 0

                    ex_data = exercices_data[idx] if exercices_data else {}
                    fragment = ex_data.get('contenu', '')
                    source = "extraction_fraiche"

                    # R√©cup√©rer les exercices structur√©s si disponibles
                    exercices_struct = analyse_complete.get("exercices_struct", []) if isinstance(analyse_complete,
                                                                                                  dict) else []

                    if exercices_struct and idx < len(exercices_struct):
                        ex_vision = exercices_struct[idx]
                        donnees_vision_exercice = {
                            "elements_visuels": ex_vision.get("schemas", []),
                            "formules_latex": ex_vision.get("formules", []),
                            "graphs": ex_vision.get("graphs", []),
                            "angles": ex_vision.get("angles", []),
                            "numbers": ex_vision.get("numbers", [])
                        }

                    logger.info(f"‚úÖ Contenu extrait via fallback")
                    logger.info(f"   - Source: {source}")
                    logger.info(f"   - Longueur: {len(fragment)} caract√®res")
                    logger.info(f"   - Sch√©mas: {len(donnees_vision_exercice.get('elements_visuels', []))}")

                    # Enregistrer la m√©thode d'extraction
                    if isinstance(analyse_complete, dict):
                        methode_extraction = analyse_complete.get('source_extraction', 'standard')
                    else:
                        methode_extraction = "standard"

                    logger.info(f"   - M√©thode extraction: {methode_extraction}")

                else:
                    logger.info(f"‚ö†Ô∏è  Texte extrait trop court: {len(texte_complet or '')} caract√®res")
            except Exception as e:
                logger.info(f"‚ùå Erreur extraction fichier: {type(e).__name__}: {str(e)[:100]}")

        extraction_time = time.time() - extraction_start

        # 4) VALIDATION DU FRAGMENT
        if not fragment or len(fragment.strip()) < 20:
            error_msg = f"Fragment invalide (longueur: {len(fragment or '')} chars, source: {source})"
            logger.info(f"‚ùå {error_msg}")
            logger.info(f"‚è±Ô∏è  Temps extraction: {extraction_time:.1f}s")

            # Mise √† jour statut erreur
            soum.statut = 'erreur'
            soum.save()

            raise ValueError(error_msg)

        logger.info(f"‚úÖ Fragment valid√©")
        logger.info(f"‚è±Ô∏è  Extraction totale: {extraction_time:.1f}s")
        logger.info(f"üìù D√©but fragment: {fragment[:100].replace(chr(10), ' ')}...")
        logger.info(f"üîß M√©thode extraction: {methode_extraction}")

        # 5) PR√âPARATION CONTEXTE IA
        mat = dem.matiere if dem.matiere else Matiere.objects.first()
        titre_exercice = f"Exercice {idx + 1}"

        # R√©cup√©ration titre depuis exercices_data si disponible
        if dem.exercices_data and source == "exercices_data":
            try:
                exercices_list = json.loads(dem.exercices_data)
                for ex in exercices_list:
                    if ex.get('index') == idx:
                        titre_exercice = ex.get('titre_complet', ex.get('titre', titre_exercice))
                        break
            except:
                pass

        contexte = f"Exercice de {mat.nom if mat else 'Mati√®re'} ‚Äì {titre_exercice}"
        if dem.departement:
            contexte += f" ‚Äì D√©partement {dem.departement.nom}"
        logger.info(f"üéØ Contexte IA: {contexte}")

        # 6) G√âN√âRATION IA AVEC GESTION D'ERREURS ROBUSTE
        ia_start = time.time()
        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"ü§ñ D√âBUT G√âN√âRATION IA AVEC SCH√âMAS")
        logger.info(f"{'‚îÄ' * 40}")

        try:
            # Appel IA avec les donn√©es vision pr√©-filtr√©es
            corrige_txt, _ = generer_corrige_ia_et_graphique(
                texte_enonce=fragment,
                contexte=contexte,
                matiere=mat,
                donnees_vision=donnees_vision_exercice if donnees_vision_exercice else None,  # ‚Üê Donn√©es filtr√©es !
                demande=dem
            )

            ia_time = time.time() - ia_start
            logger.info(f"‚úÖ G√©n√©ration IA r√©ussie ({ia_time:.1f}s)")
            logger.info(f"üìù Longueur corrig√©: {len(corrige_txt or '')} caract√®res")

            # Validation basique du corrig√©
            if not corrige_txt or len(corrige_txt.strip()) < 50:
                error_msg = f"Corrig√© trop court: {len(corrige_txt or '')} caract√®res"
                print(f"‚ö†Ô∏è  {error_msg}")
                raise ValueError(error_msg)

        except Exception as ia_error:
            ia_time = time.time() - ia_start
            logger.error(f"\n‚ùå √âCHEC G√âN√âRATION IA ({ia_time:.1f}s)")
            logger.info(f"   Type erreur: {type(ia_error).__name__}")
            logger.info(f"   Message: {str(ia_error)[:200]}")
            logger.info(f"{'‚îÄ' * 40}")

            # Retry automatique apr√®s d√©lai
            logger.info(f"üîÑ Retry automatique dans 60s...")
            raise self.retry(exc=ia_error, countdown=60)

        # 7) MISE √Ä JOUR STATUT INTERM√âDIAIRE
        soum.statut = 'formatage_pdf'
        soum.progression = 60
        soum.save()
        logger.info(f"üìä Statut mis √† jour: formatage_pdf (60%)")

        # 8) G√âN√âRATION PDF
        pdf_start = time.time()
        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üìÑ D√âBUT G√âN√âRATION PDF")
        logger.info(f"{'‚îÄ' * 40}")

        try:
            pdf_url = generer_pdf_corrige(
                {
                    "titre_corrige": contexte,
                    "corrige_html": corrige_txt,
                    "soumission_id": soum.id,
                    "titre_exercice": titre_exercice,
                    "methode_extraction": methode_extraction  # Ajout pour suivi
                },
                soum.id
            )

            pdf_time = time.time() - pdf_start
            print(f"‚úÖ G√©n√©ration PDF r√©ussie ({pdf_time:.1f}s)")
            print(f"üìé URL PDF: {pdf_url}")

        except Exception as pdf_error:
            pdf_time = time.time() - pdf_start
            logger.error(f"‚ùå √âchec g√©n√©ration PDF ({pdf_time:.1f}s)")
            logger.info(f"   Erreur: {type(pdf_error).__name__}: {str(pdf_error)[:200]}")
            raise pdf_error

        # 9) D√âBIT CR√âDIT
        debit_start = time.time()
        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üí≥ D√âBIT CR√âDIT UTILISATEUR")
        logger.info(f"{'‚îÄ' * 40}")

        try:
            if not debiter_credit_abonnement(dem.user):
                error_msg = "Cr√©dits insuffisants"
                logger.info(f"‚ùå {error_msg}")

                soum.statut = 'erreur_credit'
                soum.save()

                raise ValueError(error_msg)

            debit_time = time.time() - debit_start
            logger.info(f"‚úÖ D√©bit cr√©dit r√©ussi ({debit_time:.1f}s)")

        except Exception as debit_error:
            print(f"‚ùå Erreur d√©bit cr√©dit: {type(debit_error).__name__}")
            raise debit_error

        # 10) CR√âATION CORRIGEPARTIEL
        corrige_start = time.time()
        logger.info(f"\n{'‚îÄ' * 40}")
        logger.info(f"üìÅ CR√âATION CORRIGEPARTIEL")
        logger.info(f"{'‚îÄ' * 40}")

        try:
            # Pr√©paration titre
            titre_reel = titre_exercice
            if len(titre_reel) > 200:
                titre_reel = titre_reel[:197] + "..."

            # R√©cup√©ration chemin PDF
            pdf_relative_path = pdf_url.replace(settings.MEDIA_URL, '')
            pdf_absolute_path = os.path.join(settings.MEDIA_ROOT, pdf_relative_path)

            if not os.path.exists(pdf_absolute_path):
                error_msg = f"Fichier PDF non trouv√©: {pdf_absolute_path}"
                logger.error(f"‚ùå {error_msg}")
                raise FileNotFoundError(error_msg)

            # Cr√©ation CorrigePartiel avec info d'extraction
            with open(pdf_absolute_path, 'rb') as f:
                corrige = CorrigePartiel.objects.create(
                    soumission=soum,
                    titre_exercice=titre_reel,
                )
                corrige.fichier_pdf.save(
                    f"corrige_{dem.id}_ex{idx + 1}_{soum.id}_{int(time.time())}.pdf",
                    File(f)
                )
                corrige.save()

            corrige_time = time.time() - corrige_start
            logger.info(f"‚úÖ CorrigePartiel cr√©√© ({corrige_time:.1f}s)")
            logger.info(f"   - ID: {corrige.id}")
            logger.info(f"   - Titre: {titre_reel}")
            logger.info(f"   - M√©thode extraction: {methode_extraction}")

        except Exception as corrige_error:
            corrige_time = time.time() - corrige_start
            logger.info(f"‚ùå Erreur cr√©ation CorrigePartiel ({corrige_time:.1f}s)")
            logger.info(f"   Erreur: {type(corrige_error).__name__}: {str(corrige_error)[:200]}")
            raise corrige_error

        # 11) FINALISATION
        total_time = time.time() - task_start

        # Pr√©parer le r√©sultat JSON avec les informations des sch√©mas
        resultat_json = {
            "exercice_index": idx,
            "exercice_titre": titre_reel,
            "corrige_text": corrige_txt,
            "pdf_url": pdf_url,
            "timestamp": datetime.now().isoformat(),
            "processing_time": total_time,
            "source_content": source,
            "methode_extraction": methode_extraction,
            "departement": dem.departement.nom if dem.departement else None,
            "schemas_utilises": len(
                donnees_vision_exercice.get('elements_visuels', [])) if donnees_vision_exercice else 0
        }

        soum.statut = 'termine'
        soum.progression = 100
        soum.resultat_json = resultat_json
        soum.save()

        logger.info(f"\n{'=' * 70}")
        logger.info(f"‚úÖ T√ÇCHE TERMIN√âE AVEC SUCC√àS!")
        logger.info(f"   Temps total: {total_time:.1f}s")
        logger.info(f"   Exercice: {titre_reel}")
        logger.info(f"   Source contenu: {source}")
        logger.info(f"   M√©thode extraction: {methode_extraction}")
        logger.info(f"   Sch√©mas utilis√©s: {resultat_json['schemas_utilises']}")
        logger.info(f"   D√©partement: {dem.departement.nom if dem.departement else 'Non sp√©cifi√©'}")
        logger.info(f"   Corrig√©: {len(corrige_txt)} caract√®res")
        logger.info(f"   {datetime.now().strftime('%H:%M:%S')}")
        logger.info(f"{'=' * 70}")

        return True

    except Exception as e:
        total_time = time.time() - task_start

        logger.info(f"\n{'=' * 70}")
        logger.error(f"‚ùå ERREUR CRITIQUE DANS LA T√ÇCHE")
        logger.info(f"   Temps √©coul√©: {total_time:.1f}s")
        logger.info(f"   Type erreur: {type(e).__name__}")
        logger.info(f"   Message: {str(e)[:300]}")
        logger.info(f"   Soumission ID: {soumission_id}")
        logger.info(f"   {datetime.now().strftime('%H:%M:%S')}")
        logger.info(f"{'=' * 70}")

        # Log d√©taill√© de l'erreur
        import traceback
        error_details = traceback.format_exc()
        logger.info(f"\nüìã TRACEBACK COMPLET:")
        logger.info(error_details[:1000])  # Limit√© pour √©viter logs trop longs

        # Mise √† jour statut erreur si possible
        try:
            soum = SoumissionIA.objects.get(id=soumission_id)
            soum.statut = 'erreur'
            soum.save()
        except:
            pass

        # Si c'est une erreur r√©seau/timeout, on retry
        error_type = type(e).__name__
        if error_type in ['Timeout', 'ConnectionError', 'ReadTimeout', 'ConnectTimeout']:
            logger.error(f"üîÑ Erreur r√©seau d√©tect√©e, retry automatique...")
            raise self.retry(exc=e, countdown=120)

        # Pour les autres erreurs, on ne retry pas
        return False